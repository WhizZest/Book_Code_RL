{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "# Q网络定义\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 经验回放池\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        states, actions, rewards, next_states, dones = zip(*random.sample(self.buffer, batch_size))\n",
    "        return (\n",
    "            torch.tensor(np.stack(states), dtype=torch.float32),\n",
    "            torch.tensor(actions, dtype=torch.int64),\n",
    "            torch.tensor(rewards, dtype=torch.float32),\n",
    "            torch.tensor(np.stack(next_states), dtype=torch.float32),\n",
    "            torch.tensor(dones, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_dataList(rewards, xStart=0):\n",
    "    # 设置图像的宽度为 12 英寸\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.plot(range(xStart, len(rewards) + xStart), rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Total Reward vs Episode')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.V = nn.Linear(128, 1)\n",
    "        self.A = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        V = self.V(x)\n",
    "        A = self.A(x)\n",
    "        Q = V + (A - A.mean(dim=1, keepdim=True))\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6):\n",
    "        \"\"\"\n",
    "        capacity: 缓冲区容量\n",
    "        alpha: 优先级比例，0表示完全随机采样，1表示完全按优先级采样\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.priorities = np.zeros((capacity,), dtype=np.float32)\n",
    "        self.position = 0\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"添加新经验，优先级初始化为最大值以确保被采样\"\"\"\n",
    "        max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append((state, action, reward, next_state, done))\n",
    "        else:\n",
    "            self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.priorities[self.position] = max_priority\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        \"\"\"\n",
    "        采样带优先级的批次数据\n",
    "        beta: 重要性采样的偏置修正参数\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == self.capacity:\n",
    "            priorities = self.priorities\n",
    "        else:\n",
    "            priorities = self.priorities[:self.position]\n",
    "        \n",
    "        # 根据优先级分布计算采样概率\n",
    "        probs = priorities ** self.alpha\n",
    "        probs /= probs.sum()\n",
    "\n",
    "        # 按照概率采样\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[idx] for idx in indices]\n",
    "\n",
    "        # 计算重要性采样权重\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()\n",
    "\n",
    "        # 解包样本\n",
    "        states, actions, rewards, next_states, dones = zip(*samples)\n",
    "        return (\n",
    "            torch.tensor(np.stack(states), dtype=torch.float32),\n",
    "            torch.tensor(actions, dtype=torch.int64),\n",
    "            torch.tensor(rewards, dtype=torch.float32),\n",
    "            torch.tensor(np.stack(next_states), dtype=torch.float32),\n",
    "            torch.tensor(dones, dtype=torch.float32),\n",
    "            torch.tensor(weights, dtype=torch.float32),\n",
    "            indices,\n",
    "        )\n",
    "\n",
    "    def update_priorities(self, indices, priorities):\n",
    "        \"\"\"根据新的 TD Error 更新优先级\"\"\"\n",
    "        self.priorities[indices] = priorities\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, std_init=0.5):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        # 可训练参数\n",
    "        self.weight_mu = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.bias_mu = nn.Parameter(torch.empty(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.empty(out_features))\n",
    "\n",
    "        # 非参数化噪声\n",
    "        self.register_buffer(\"weight_epsilon\", torch.empty(out_features, in_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.empty(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # 初始化可训练参数\n",
    "        bound = 1 / self.in_features ** 0.5\n",
    "        self.weight_mu.data.uniform_(-bound, bound)\n",
    "        self.weight_sigma.data.fill_(self.std_init / (self.in_features ** 0.5))\n",
    "        self.bias_mu.data.uniform_(-bound, bound)\n",
    "        self.bias_sigma.data.fill_(self.std_init / (self.in_features ** 0.5))\n",
    "\n",
    "    def reset_noise(self):\n",
    "        # 采样噪声\n",
    "        self.weight_epsilon.normal_()\n",
    "        self.bias_epsilon.normal_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            weight = self.weight_mu + self.weight_sigma * self.weight_epsilon\n",
    "            bias = self.bias_mu + self.bias_sigma * self.bias_epsilon\n",
    "        else:\n",
    "            weight = self.weight_mu\n",
    "            bias = self.bias_mu\n",
    "        return torch.nn.functional.linear(x, weight, bias)\n",
    "\n",
    "class Dueling_NoisyDQN(nn.Module):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super(Dueling_NoisyDQN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),  # (C, H, W) -> Conv,输出：32@20x20\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), # 输出：64@9x9\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1), # 输出：64@7x7\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 计算卷积后的特征图的尺寸\n",
    "        conv_output_size = self._get_conv_output_size(input_shape)\n",
    "\n",
    "        # Noisy 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            NoisyLinear(conv_output_size, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Dueling 分支\n",
    "        self.V = NoisyLinear(512, 1)            # 状态价值分支\n",
    "        self.A = NoisyLinear(512, output_dim)   # 优势值分支\n",
    "\n",
    "    def _get_conv_output_size(self, shape):\n",
    "        x = torch.zeros(1, *shape)  # 临时张量用于计算\n",
    "        x = self.conv(x)\n",
    "        return int(torch.flatten(x, 1).size(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)  # 展平为向量\n",
    "        x = self.fc(x)\n",
    "\n",
    "        V = self.V(x)\n",
    "        A = self.A(x)\n",
    "        Q = V + (A - A.mean(dim=1, keepdim=True))\n",
    "        return Q\n",
    "\n",
    "    def reset_noise(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, NoisyLinear):\n",
    "                m.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepPrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6, n_step=3, gamma=0.99):\n",
    "        \"\"\"\n",
    "        capacity: 缓冲区容量\n",
    "        alpha: 优先级比例，0表示完全随机采样，1表示完全按优先级采样\n",
    "        n_step: 多步时间跨度\n",
    "        gamma: 折扣因子\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.priorities = np.zeros((capacity,), dtype=np.float32)\n",
    "        self.position = 0\n",
    "        self.alpha = alpha\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # 用于多步存储的临时队列\n",
    "        self.n_step_queue = []\n",
    "\n",
    "    def _get_n_step_info(self):\n",
    "        \"\"\"从 n_step_queue 计算 n 步累计奖励和目标状态\"\"\"\n",
    "        R = 0\n",
    "        for idx, (_, _, reward, _, _) in enumerate(self.n_step_queue):\n",
    "            R += (self.gamma ** idx) * reward\n",
    "        state, action, _, next_state, done = self.n_step_queue[0]\n",
    "        final_next_state, final_done = self.n_step_queue[-1][3], self.n_step_queue[-1][4]\n",
    "        return (state, action, R, final_next_state, final_done)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        添加新经验。\n",
    "        使用 n_step_queue 缓存多步数据，只有在积累到 n 步时才存入 buffer。\n",
    "        在轨迹结束时处理剩余的队列。\n",
    "        \"\"\"\n",
    "        self.n_step_queue.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        # 如果 n_step_queue 满了，处理一个完整的 n-step 转移\n",
    "        if len(self.n_step_queue) == self.n_step:\n",
    "            n_step_transition = self._get_n_step_info()\n",
    "            max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "            if len(self.buffer) < self.capacity:\n",
    "                self.buffer.append(n_step_transition)\n",
    "            else:\n",
    "                self.buffer[self.position] = n_step_transition\n",
    "            self.priorities[self.position] = max_priority\n",
    "            self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "            # 移除队列的第一个元素\n",
    "            self.n_step_queue.pop(0)\n",
    "\n",
    "        # 如果 done=True，处理剩余队列中的短步转移\n",
    "        if done:\n",
    "            while self.n_step_queue:\n",
    "                n_step_transition = self._get_n_step_info()\n",
    "                max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "                if len(self.buffer) < self.capacity:\n",
    "                    self.buffer.append(n_step_transition)\n",
    "                else:\n",
    "                    self.buffer[self.position] = n_step_transition\n",
    "                self.priorities[self.position] = max_priority\n",
    "                self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "                # 移除队列的第一个元素\n",
    "                self.n_step_queue.pop(0)\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4, device='cpu'):\n",
    "        \"\"\"\n",
    "        采样带优先级的批次数据。\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == self.capacity:\n",
    "            priorities = self.priorities\n",
    "        else:\n",
    "            priorities = self.priorities[:self.position]\n",
    "\n",
    "        # 根据优先级分布计算采样概率\n",
    "        probs = priorities ** self.alpha\n",
    "        probs /= probs.sum()\n",
    "\n",
    "        # 按照概率采样\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[idx] for idx in indices]\n",
    "\n",
    "        # 计算重要性采样权重\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()\n",
    "\n",
    "        # 解包样本\n",
    "        states, actions, rewards, next_states, dones = zip(*samples)\n",
    "        return (\n",
    "            torch.tensor(np.stack(states), dtype=torch.float32).to(device),\n",
    "            torch.tensor(actions, dtype=torch.int64).to(device),\n",
    "            torch.tensor(rewards, dtype=torch.float32).to(device),\n",
    "            torch.tensor(np.stack(next_states), dtype=torch.float32).to(device),\n",
    "            torch.tensor(dones, dtype=torch.float32).to(device),\n",
    "            torch.tensor(weights, dtype=torch.float32).to(device),\n",
    "            indices,\n",
    "        )\n",
    "\n",
    "    def update_priorities(self, indices, priorities):\n",
    "        \"\"\"根据新的 TD Error 更新优先级\"\"\"\n",
    "        self.priorities[indices] = priorities\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def current_queue_size(self):\n",
    "        return len(self.n_step_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess_image(frame, method='binarize'):\n",
    "    # 预处理图像：背景黑化(颜色值为200的像素点设为黑色)、灰度化、裁剪、缩放、二值化\n",
    "    frame[frame == 200] = 0\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_cropped = frame_gray[:, :420]  # 裁剪掉地面部分\n",
    "    frame_resize = cv2.resize(frame_cropped, (84, 84))\n",
    "    if method == 'binarize':\n",
    "        processed_frame = cv2.threshold(frame_resize, 1, 255, cv2.THRESH_BINARY)[1]\n",
    "    else:\n",
    "        # 归一化到 [0, 1]\n",
    "        processed_frame = frame_resize / 255.0\n",
    "    return processed_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.3 (SDL 2.0.16, Python 3.8.20)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pygame\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import configparser\n",
    "\n",
    "fileName = 'models/fb_v0_no_score_2024-12-10_21-45-31.pth'\n",
    "bestScoreFileName = 'flappy_bird_v0_model_best_score.pth'\n",
    "stopTrainingFileName = 'flappy_bird_stop.txt'\n",
    "guideFileName = 'result1/models/fb_v0_no_score_2024-12-07_16-37-46.pth'\n",
    "\n",
    "def train_dueling_dqn_noise_MultiStep_PER(env, num_episodes=500, batch_size=64, gamma=0.99, \n",
    "                                          epsilon_schedule=[(0, 1.0), (20000, 0.1), (700000, 0.01), (1040000, 0.001), (1720000, 0.0001), (2060000, 0.0)], \n",
    "                                          lr=1e-3, alpha=0.6, beta_start=0.4, beta_increment=1e-4, \n",
    "                                          number_of_states=4, preprocessHeight=84, preprocessWidth=84, skip_frames=1):\n",
    "    # 新的状态维度为原始状态维度的 number_of_states 倍\n",
    "    input_shape = (number_of_states, preprocessHeight, preprocessWidth)\n",
    "    output_dim = env.action_space.n\n",
    "\n",
    "    # 检查是否有GPU可用\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    q_net = Dueling_NoisyDQN(input_shape, output_dim).to(device)\n",
    "    # 判断是否存在fileName文件\n",
    "    if os.path.exists(fileName):\n",
    "        q_net.load_state_dict(torch.load(fileName, weights_only=True, map_location=device))\n",
    "        print(\"模型已加载\")\n",
    "    q_net.train() # 设置为训练模式，需要通过训练更新参数，该行代码可以省略，因为默认就是训练模式\n",
    "    target_net = Dueling_NoisyDQN(input_shape, output_dim).to(device)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "    target_net.eval() # 设置为评估模式，不需要通过训练更新参数，更新时只需要复制q_net的参数\n",
    "\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=lr)\n",
    "    replay_buffer_capacity = 100000\n",
    "    replay_buffer = MultiStepPrioritizedReplayBuffer(capacity=replay_buffer_capacity, alpha=alpha, n_step=20, gamma=gamma)\n",
    "    epsilon = epsilon_schedule[0][1]\n",
    "    beta = beta_start\n",
    "    rewards = []  # 确保它是一个列表\n",
    "    max_reward_total = -np.inf\n",
    "    max_interval_rewards = -np.inf\n",
    "    min_interval_rewards = np.inf\n",
    "    max_score = 0\n",
    "    max_step_count = 0\n",
    "    update_step_count = 0\n",
    "    update_step_interval = 200\n",
    "    print_interval = 300  # 间隔（单位：秒）\n",
    "    # 记录训练开始的时间\n",
    "    last_save_time = time.time()\n",
    "    last_print_time = last_save_time\n",
    "    stop_training = False\n",
    "    steps_Interval = 1000\n",
    "    steps_perInterval = 0\n",
    "    steps_total = 0\n",
    "    loss_perInterval = 0\n",
    "    q_value_perInterval = 0\n",
    "    delta_training_frequency = 3\n",
    "    delta_loss_threshold = 0.1\n",
    "    # 获取当前时间戳\n",
    "    current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    csv_file = f'dueling_dqn_noise_MultiStep_PER_{current_time_str}.csv'\n",
    "    aim_score = 10\n",
    "\n",
    "    # 创建表格文件，列名分别为：总步数、epsilon、平均损失、平均Q值\n",
    "    with open(csv_file, 'w') as f:\n",
    "        f.write('Time,episode,Steps,epsilon,loss,Q_value\\n')\n",
    "        f.close()\n",
    "    ratio_schedule = []\n",
    "    for i in range(len(epsilon_schedule) - 1):\n",
    "        start_step, start_epsilon = epsilon_schedule[i]\n",
    "        end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "        ratio = (end_epsilon - start_epsilon) / (end_step - start_step)\n",
    "        ratio_schedule.append(ratio)\n",
    "    \n",
    "    print(f\"Episode | min interval reward | max interval reward | max_reward_total | Epsilon | max_score | steps_total | lr | update_step_interval | training_frequency | loss_threshold | beta | replay_buffer.size\")\n",
    "    for episode in range(num_episodes):\n",
    "        raw_state = env.reset()  # 返回 numpy.ndarray\n",
    "        processed_frame = preprocess_image(raw_state)\n",
    "        state_queue = deque([processed_frame.copy() for _ in range(number_of_states)], maxlen=number_of_states)  # 初始化队列，初始状态填充队列\n",
    "        state = np.array(state_queue)\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        step_count = 0\n",
    "        reward_perSkip = 0\n",
    "        score = 0\n",
    "\n",
    "        while not done:  # 每个 episode 的最大步数\n",
    "            # 根据多段线性衰减策略计算 epsilon\n",
    "            for i in range(len(epsilon_schedule) - 1):\n",
    "                start_step, start_epsilon = epsilon_schedule[i]\n",
    "                end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "                if start_step <= steps_total < end_step:\n",
    "                    # 在当前阶段内进行线性插值\n",
    "                    ratio = ratio_schedule[i]\n",
    "                    epsilon = max(start_epsilon + ratio * (steps_total - start_step), end_epsilon)\n",
    "            # 跳帧处理\n",
    "            bSkip = True\n",
    "            if step_count % skip_frames == 0:\n",
    "                bSkip = False\n",
    "                reward_perSkip = 0\n",
    "                # ε-贪婪策略\n",
    "                if random.random() < epsilon:\n",
    "                    # 根据概率决定采样\n",
    "                    if random.random() < 0.08 * skip_frames:\n",
    "                        action = 1\n",
    "                    else:\n",
    "                        action = 0\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        action = q_net(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)).argmax().item()\n",
    "            else:\n",
    "                action = 0\n",
    "\n",
    "            # 执行动作\n",
    "            next_raw_state, reward, done, info = env.step(action)\n",
    "            step_count += 1\n",
    "            steps_total += 1\n",
    "            if max_step_count < step_count:\n",
    "                max_step_count = step_count\n",
    "            raw_state = next_raw_state\n",
    "            if done:\n",
    "                bSkip = False\n",
    "            if bSkip == False:\n",
    "                # 更新状态队列\n",
    "                processed_frame = preprocess_image(raw_state)\n",
    "                state_queue.append(processed_frame)\n",
    "                next_state = np.array(state_queue)\n",
    "            reward = reward * 0.1  # 缩放奖励\n",
    "            # 得分\n",
    "            bScore = False\n",
    "            if info['score'] > score:\n",
    "                reward += 0.4  # 奖励增加\n",
    "                score = info['score']\n",
    "                bScore = True\n",
    "                if score % aim_score == 0:\n",
    "                    bSkip = False\n",
    "            if info['score'] > max_score:\n",
    "                max_score = info['score']\n",
    "                if max_score > 100:\n",
    "                    torch.save(q_net.state_dict(), bestScoreFileName) # 保存模型\n",
    "            if done:\n",
    "                reward -= 0.2  # 惩罚\n",
    "            reward_perSkip += reward\n",
    "            if bSkip == False:\n",
    "                if bScore:\n",
    "                    if score % aim_score == 0:\n",
    "                        replay_buffer.add(state, action, reward_perSkip, next_state, True) # 得到aim_score分结束，否则轨迹越长，Q值越大，无法收敛\n",
    "                    else:\n",
    "                        replay_buffer.add(state, action, reward_perSkip, next_state, done)\n",
    "                else:\n",
    "                    replay_buffer.add(state, action, reward_perSkip, next_state, done)\n",
    "                state = next_state\n",
    "            total_reward += reward\n",
    "            if total_reward > max_reward_total:\n",
    "                max_reward_total = total_reward\n",
    "            if max_interval_rewards < total_reward:\n",
    "                max_interval_rewards = total_reward\n",
    "\n",
    "            # 经验回放训练\n",
    "            if replay_buffer.size() >= batch_size and bSkip == False:\n",
    "                training_frequency = 1\n",
    "                loss_threshold = 0.5\n",
    "                while training_frequency > 0:\n",
    "                    # 从优先级缓冲区中采样\n",
    "                    states, actions, rewards_batch, next_states, dones, weights, indices = replay_buffer.sample(batch_size, beta, device)\n",
    "\n",
    "                    q_values = q_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "                    with torch.no_grad():\n",
    "                        q_value_perInterval += q_values.mean().item() / steps_Interval\n",
    "                        best_actions = q_net(next_states).argmax(1)  # 使用当前网络选择最大Q值的动作\n",
    "                        target_q_values = rewards_batch + gamma * (1 - dones) * target_net(next_states).gather(1, best_actions.unsqueeze(1)).squeeze(1)\n",
    "                    # 计算 TD Error\n",
    "                    td_errors = target_q_values - q_values\n",
    "                    loss = (weights * td_errors.pow(2)).mean()\n",
    "                    loss_perInterval += loss.item() / steps_Interval\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # 更新优先级\n",
    "                    priorities = td_errors.abs().detach().cpu().numpy()\n",
    "                    replay_buffer.update_priorities(indices, priorities)\n",
    "                    update_step_count += 1\n",
    "                    steps_perInterval += 1\n",
    "                \n",
    "                    # 更新目标网络\n",
    "                    if update_step_count >= update_step_interval:\n",
    "                        update_step_count = 0\n",
    "                        target_net.load_state_dict(q_net.state_dict()) # 将q_net的参数复制到target_net中\n",
    "                    training_frequency -= 1\n",
    "                    if loss.item() > loss_threshold and replay_buffer.size() >= replay_buffer_capacity * 0.5 and training_frequency == 0: # 如果损失大于阈值，且经验池已足够大，则重复训练，暂停与环境互动\n",
    "                        training_frequency += delta_training_frequency\n",
    "                        loss_threshold += delta_loss_threshold\n",
    "                    if steps_perInterval >= steps_Interval:\n",
    "                        # 追加数据到 CSV 文件\n",
    "                        with open(csv_file, 'a') as f:\n",
    "                            current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                            f.write(f'{current_time_str},{episode},{steps_total},{epsilon},{loss_perInterval},{q_value_perInterval}\\n')\n",
    "                        steps_perInterval = 0\n",
    "                        loss_perInterval = 0\n",
    "                        q_value_perInterval = 0\n",
    "                    # 检查时间间隔\n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_save_time > 60:\n",
    "                        # 读取配置文件\n",
    "                        config = configparser.ConfigParser()\n",
    "                        if config.read('config.ini'):\n",
    "                            update_step_interval = config.getint('Training', 'update_step_interval')\n",
    "                            delta_training_frequency_temp = config.getint('Training', 'delta_training_frequency')\n",
    "                            if delta_training_frequency_temp >= 0:\n",
    "                                delta_training_frequency = delta_training_frequency_temp\n",
    "                            delta_loss_threshold_temp = config.getfloat('Training', 'delta_loss_threshold')\n",
    "                            if delta_loss_threshold_temp > 0:\n",
    "                                delta_loss_threshold = delta_loss_threshold_temp\n",
    "                            lr_temp = config.getfloat('Training', 'lr')\n",
    "                            if lr_temp > 0:\n",
    "                                lr = lr_temp\n",
    "                                state_dict = optimizer.state_dict()\n",
    "                                state_dict['param_groups'][0]['lr'] = lr\n",
    "                                optimizer.load_state_dict(state_dict)\n",
    "                            beta_temp = config.getfloat('Training', 'beta')\n",
    "                            if beta_temp > 0:\n",
    "                                beta = beta_temp\n",
    "                            stop_training = config.getboolean('Training', 'stop_training')\n",
    "                            guideOpen = config.getboolean('Training', 'guideOpen')\n",
    "                            \n",
    "                        # 设置保存路径和合法文件名\n",
    "                        save_path = \"./models\"\n",
    "                        os.makedirs(save_path, exist_ok=True)  # 确保路径存在\n",
    "                        current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')  # 使用合法字符\n",
    "                        currentNetFile = os.path.join(save_path, f'fb_rgb_v0_{current_time_str}.pth')\n",
    "                        torch.save(q_net.state_dict(), currentNetFile) # 保存模型\n",
    "                        last_save_time = current_time\n",
    "                    if current_time - last_print_time >= print_interval:\n",
    "                        last_print_time = current_time\n",
    "                        print(f\"{episode} | {min_interval_rewards:.3f} | {max_interval_rewards:.3f} | {max_reward_total:.3f} | {epsilon:.5f} | {max_score} | {steps_total} | {lr:.8e} | {update_step_interval} | {training_frequency} | {loss_threshold:.3f} | {beta:.5f} | {replay_buffer.size()}\")\n",
    "                        min_interval_rewards = np.inf\n",
    "                        max_interval_rewards = -np.inf\n",
    "                    # 更新 beta\n",
    "                    beta = min(1.0, beta + beta_increment)\n",
    "\n",
    "        rewards.append(total_reward)  # 确保 append 正常工作\n",
    "        if min_interval_rewards > total_reward:\n",
    "            min_interval_rewards = total_reward\n",
    "        # 重置噪声\n",
    "        q_net.reset_noise()\n",
    "        target_net.reset_noise()\n",
    "        if stop_training:\n",
    "            # 把配置文件的stop_training改为False\n",
    "            config['Training']['stop_training'] = 'False'\n",
    "            with open('config.ini', 'w') as configfile:\n",
    "                config.write(configfile)\n",
    "            break\n",
    "\n",
    "    return q_net, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Dueling_Noisy_DistributionalDQN(nn.Module):\n",
    "    def __init__(self, input_shape, output_dim, num_atoms=51):\n",
    "        super(Dueling_Noisy_DistributionalDQN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),  # (C, H, W) -> Conv,输出：32@20x20\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), # 输出：64@9x9\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1), # 输出：64@7x7\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 计算卷积后的特征图的尺寸\n",
    "        conv_output_size = self._get_conv_output_size(input_shape)\n",
    "\n",
    "        # Noisy 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            NoisyLinear(conv_output_size, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Dueling 分支\n",
    "        self.V = NoisyLinear(512, num_atoms)            # 状态价值分支\n",
    "        self.A = NoisyLinear(512, output_dim * num_atoms)   # 优势值分支\n",
    "        self.num_atoms = num_atoms\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def _get_conv_output_size(self, shape):\n",
    "        x = torch.zeros(1, *shape)  # 临时张量用于计算\n",
    "        x = self.conv(x)\n",
    "        return int(torch.flatten(x, 1).size(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)  # 展平为向量\n",
    "        x = self.fc(x)\n",
    "\n",
    "        V = self.V(x).view(-1, 1, self.num_atoms)\n",
    "        A = self.A(x).view(-1, self.output_dim, self.num_atoms)\n",
    "        Q = V + (A - A.mean(dim=1, keepdim=True))\n",
    "        Q_prob = F.softmax(Q, dim=2) # 将 Q 值转换为概率分布\n",
    "        return Q_prob\n",
    "\n",
    "    def reset_noise(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, NoisyLinear):\n",
    "                m.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_distribution(next_dist, rewards, dones, gamma, atoms, v_min, v_max, delta_z, support):\n",
    "    \"\"\"\n",
    "    投影 Bellman 更新后的分布到支持点。\n",
    "    \"\"\"\n",
    "    #delta_z = (v_max - v_min) / (atoms - 1)\n",
    "    #support = torch.linspace(v_min, v_max, atoms).to(next_dist.device)  # Shape: (atoms,)\n",
    "    \n",
    "    batch_size = rewards.size(0)\n",
    "    next_support = rewards.unsqueeze(1) + gamma * support.unsqueeze(0) * (1 - dones.unsqueeze(1))  # Shape: (batch_size, atoms)\n",
    "    next_support = next_support.clamp(v_min, v_max)  # 限制范围\n",
    "\n",
    "    b = (next_support - v_min) / delta_z  # Shape: (batch_size, atoms)\n",
    "    l = b.floor().long()  # Shape: (batch_size, atoms)\n",
    "    u = b.ceil().long()  # Shape: (batch_size, atoms)\n",
    "    \n",
    "    # 修正索引的范围，确保不越界\n",
    "    l = l.clamp(0, atoms - 1)\n",
    "    u = u.clamp(0, atoms - 1)\n",
    "    \n",
    "    proj_dist = torch.zeros(batch_size, atoms).to(next_dist.device)  # Shape: (batch_size, atoms)\n",
    "\n",
    "    for i in range(atoms):  # 遍历每个支持点\n",
    "        # 注意：next_dist[:, i] 实际是 batch_size 的第 i 列 (shape: [batch_size])\n",
    "        # next_dist 应被广播以匹配 l 和 u 的维度\n",
    "        weight_left = (u[:, i] - b[:, i]).unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "        weight_right = (b[:, i] - l[:, i]).unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "        \n",
    "        proj_dist.scatter_add_(1, l[:, i].unsqueeze(1), next_dist[:, i].unsqueeze(1) * weight_left)\n",
    "        proj_dist.scatter_add_(1, u[:, i].unsqueeze(1), next_dist[:, i].unsqueeze(1) * weight_right)\n",
    "\n",
    "    # 归一化分布\n",
    "    proj_dist /= proj_dist.sum(dim=1, keepdim=True) + 1e-8  # 防止除零\n",
    "    return proj_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rainbow_dqn(env, num_episodes=500, batch_size=64, gamma=0.99, \n",
    "                    epsilon_schedule=[(0, 1.0), (20000, 0.1), (700000, 0.01), (1040000, 0.001), (1720000, 0.0001), (2060000, 0.0)], \n",
    "                    lr=1e-3, alpha=0.6, beta_start=0.4, beta_increment=1e-4, \n",
    "                    number_of_states=4, preprocessHeight=84, preprocessWidth=84, skip_frames=1,\n",
    "                    atoms=51, v_min=-10, v_max=10,\n",
    "                    modelFile = None):\n",
    "    # 新的状态维度为原始状态维度的 number_of_states 倍\n",
    "    input_shape = (number_of_states, preprocessHeight, preprocessWidth)\n",
    "    output_dim = env.action_space.n\n",
    "\n",
    "    # 检查是否有GPU可用\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    q_net = Dueling_Noisy_DistributionalDQN(input_shape, output_dim, atoms).to(device)\n",
    "    # 判断是否存在modelFile文件\n",
    "    if modelFile and os.path.exists(modelFile):\n",
    "        q_net.load_state_dict(torch.load(modelFile, weights_only=True, map_location=device))\n",
    "        print(\"模型已加载\")\n",
    "    q_net.train() # 设置为训练模式，需要通过训练更新参数，该行代码可以省略，因为默认就是训练模式\n",
    "    target_net = Dueling_Noisy_DistributionalDQN(input_shape, output_dim, atoms).to(device)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "    target_net.eval() # 设置为评估模式，不需要通过训练更新参数，更新时只需要复制q_net的参数\n",
    "\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=lr)\n",
    "    replay_buffer_capacity = 100000\n",
    "    replay_buffer = MultiStepPrioritizedReplayBuffer(capacity=replay_buffer_capacity, alpha=alpha, n_step=20, gamma=gamma)\n",
    "    delta_z = (v_max - v_min) / (atoms - 1)\n",
    "    supports = torch.linspace(v_min, v_max, atoms).to(device)\n",
    "    epsilon = epsilon_schedule[0][1]\n",
    "    beta = beta_start\n",
    "    rewards = []  # 确保它是一个列表\n",
    "    max_reward_total = -np.inf\n",
    "    max_interval_rewards = -np.inf\n",
    "    min_interval_rewards = np.inf\n",
    "    max_score = 0\n",
    "    max_step_count = 0\n",
    "    update_step_count = 0\n",
    "    update_step_interval = 200\n",
    "    print_interval = 300  # 间隔（单位：秒）\n",
    "    # 记录训练开始的时间\n",
    "    last_save_time = time.time()\n",
    "    last_print_time = last_save_time\n",
    "    stop_training = False\n",
    "    steps_Interval = 1000\n",
    "    steps_perInterval = 0\n",
    "    steps_total = 0\n",
    "    loss_perInterval = 0\n",
    "    q_value_perInterval = 0\n",
    "    delta_training_frequency = 3\n",
    "    delta_loss_threshold = 0.1\n",
    "    loss_threshold = 0.5\n",
    "    # 获取当前时间戳\n",
    "    current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    csv_file = f'dueling_dqn_noise_MultiStep_PER_{current_time_str}.csv'\n",
    "\n",
    "    # 创建表格文件，列名分别为：总步数、epsilon、平均损失、平均Q值\n",
    "    with open(csv_file, 'w') as f:\n",
    "        f.write('Time,episode,Steps,epsilon,loss,Q_value\\n')\n",
    "        f.close()\n",
    "    ratio_schedule = []\n",
    "    for i in range(len(epsilon_schedule) - 1):\n",
    "        start_step, start_epsilon = epsilon_schedule[i]\n",
    "        end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "        ratio = (end_epsilon - start_epsilon) / (end_step - start_step)\n",
    "        ratio_schedule.append(ratio)\n",
    "    \n",
    "    print(f\"Episode | min interval reward | max interval reward | max_reward_total | Epsilon | max_score | steps_total | lr | update_step_interval | training_frequency | loss_threshold | beta | replay_buffer.size\")\n",
    "    for episode in range(num_episodes):\n",
    "        raw_state = env.reset()  # 返回 numpy.ndarray\n",
    "        processed_frame = preprocess_image(raw_state)\n",
    "        state_queue = deque([processed_frame.copy() for _ in range(number_of_states)], maxlen=number_of_states)  # 初始化队列，初始状态填充队列\n",
    "        state = np.array(state_queue)\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        step_count = 0\n",
    "        reward_perSkip = 0\n",
    "        score = 0\n",
    "\n",
    "        while not done:  # 每个 episode 的最大步数\n",
    "            # 根据多段线性衰减策略计算 epsilon\n",
    "            for i in range(len(epsilon_schedule) - 1):\n",
    "                start_step, start_epsilon = epsilon_schedule[i]\n",
    "                end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "                if start_step <= steps_total < end_step:\n",
    "                    # 在当前阶段内进行线性插值\n",
    "                    ratio = ratio_schedule[i]\n",
    "                    epsilon = max(start_epsilon + ratio * (steps_total - start_step), end_epsilon)\n",
    "            # 跳帧处理\n",
    "            if step_count % skip_frames == 0:\n",
    "                reward_perSkip = 0\n",
    "                # ε-贪婪策略\n",
    "                if random.random() < epsilon:\n",
    "                    # 根据概率决定采样\n",
    "                    if random.random() < 0.08 * skip_frames:\n",
    "                        action = 1\n",
    "                    else:\n",
    "                        action = 0\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        dist = q_net(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device))\n",
    "                        action = (dist * supports).sum(dim=2).argmax().item()\n",
    "            else:\n",
    "                action = 0\n",
    "\n",
    "            # 执行动作\n",
    "            next_raw_state, reward, done, info = env.step(action)\n",
    "            step_count += 1\n",
    "            steps_total += 1\n",
    "            bSkip = True\n",
    "            if step_count % skip_frames == 0:\n",
    "                bSkip = False\n",
    "            if max_step_count < step_count:\n",
    "                max_step_count = step_count\n",
    "            raw_state = next_raw_state\n",
    "            if done:\n",
    "                bSkip = False\n",
    "            if bSkip == False:\n",
    "                # 更新状态队列\n",
    "                processed_frame = preprocess_image(raw_state)\n",
    "                state_queue.append(processed_frame)\n",
    "                next_state = np.array(state_queue)\n",
    "            reward = reward * 0.01  # 缩放奖励\n",
    "            # 得分\n",
    "            bScore = False\n",
    "            if info['score'] > score:\n",
    "                reward += 0.04  # 奖励增加\n",
    "                score = info['score']\n",
    "                bScore = True\n",
    "            if info['score'] > max_score:\n",
    "                max_score = info['score']\n",
    "                if max_score > 100:\n",
    "                    torch.save(q_net.state_dict(), bestScoreFileName) # 保存模型\n",
    "            if done:\n",
    "                reward -= 0.02  # 惩罚\n",
    "            reward_perSkip += reward\n",
    "            if bSkip == False:\n",
    "                replay_buffer.add(state, action, reward_perSkip, next_state, done)\n",
    "                state = next_state\n",
    "            total_reward += reward\n",
    "            if total_reward > max_reward_total:\n",
    "                max_reward_total = total_reward\n",
    "            if max_interval_rewards < total_reward:\n",
    "                max_interval_rewards = total_reward\n",
    "\n",
    "            # 经验回放训练\n",
    "            if replay_buffer.size() >= replay_buffer_capacity * 0.1 and bSkip == False:\n",
    "                training_frequency = 1\n",
    "                \n",
    "                while training_frequency > 0:\n",
    "                    # 从优先级缓冲区中采样\n",
    "                    states, actions, rewards_batch, next_states, dones, weights, indices = replay_buffer.sample(batch_size, beta, device)\n",
    "\n",
    "                    # 计算 Q 网络的分布\n",
    "                    dist = q_net(states)\n",
    "                    q_dist = dist[range(batch_size), actions]\n",
    "                    with torch.no_grad():\n",
    "                        # 目标网络输出分布\n",
    "                        next_dist = target_net(next_states)  # Shape: (batch_size, num_actions, atoms)\n",
    "                        # 行为网络选择动作（Double-DQN）\n",
    "                        next_q_values = (q_net(next_states) * supports).sum(dim=2)  # Shape: (batch_size, num_actions)\n",
    "                        q_value_perInterval += next_q_values.mean().item() / steps_Interval\n",
    "                        next_actions = next_q_values.argmax(dim=1)  # Shape: (batch_size,)\n",
    "                        # 根据行为网络选择的动作提取目标分布\n",
    "                        next_dist = next_dist[range(batch_size), next_actions]  # Shape: (batch_size, atoms)\n",
    "\n",
    "                        # 投影分布\n",
    "                        target_dist = projection_distribution(next_dist, rewards_batch, dones, gamma, atoms, v_min, v_max, delta_z, supports)\n",
    "                    # KL 散度损失\n",
    "                    loss = -(target_dist * q_dist.log()).sum(dim=1) * weights\n",
    "                    loss = loss.mean()\n",
    "                    loss_perInterval += loss.item() / steps_Interval\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # 更新优先级\n",
    "                    # Wasserstein 距离计算\n",
    "                    td_errors = torch.sum((target_dist - q_dist) * supports, dim=1)  # [batch_size]\n",
    "                    priorities = td_errors.abs().detach().cpu().numpy()\n",
    "                    replay_buffer.update_priorities(indices, priorities)\n",
    "                    update_step_count += 1\n",
    "                    steps_perInterval += 1\n",
    "                \n",
    "                    # 更新目标网络\n",
    "                    if update_step_count >= update_step_interval:\n",
    "                        update_step_count = 0\n",
    "                        target_net.load_state_dict(q_net.state_dict()) # 将q_net的参数复制到target_net中\n",
    "                    training_frequency -= 1\n",
    "                    if loss.item() > loss_threshold and replay_buffer.size() >= replay_buffer_capacity * 0.5 and training_frequency == 0: # 如果损失大于阈值，且经验池已足够大，则重复训练，暂停与环境互动\n",
    "                        training_frequency += delta_training_frequency\n",
    "                        loss_threshold += delta_loss_threshold\n",
    "                    if steps_perInterval >= steps_Interval:\n",
    "                        # 追加数据到 CSV 文件\n",
    "                        with open(csv_file, 'a') as f:\n",
    "                            current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                            f.write(f'{current_time_str},{episode},{steps_total},{epsilon},{loss_perInterval},{q_value_perInterval}\\n')\n",
    "                        steps_perInterval = 0\n",
    "                        loss_perInterval = 0\n",
    "                        q_value_perInterval = 0\n",
    "                    # 检查时间间隔\n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_save_time > 60:\n",
    "                        # 读取配置文件\n",
    "                        config = configparser.ConfigParser()\n",
    "                        if config.read('config.ini'):\n",
    "                            update_step_interval = config.getint('Training', 'update_step_interval')\n",
    "                            delta_training_frequency_temp = config.getint('Training', 'delta_training_frequency')\n",
    "                            if delta_training_frequency_temp >= 0:\n",
    "                                delta_training_frequency = delta_training_frequency_temp\n",
    "                            delta_loss_threshold_temp = config.getfloat('Training', 'delta_loss_threshold')\n",
    "                            if delta_loss_threshold_temp > 0:\n",
    "                                delta_loss_threshold = delta_loss_threshold_temp\n",
    "                            loss_threshold = config.getfloat('Training', 'loss_threshold')\n",
    "                            lr_temp = config.getfloat('Training', 'lr')\n",
    "                            if lr_temp > 0:\n",
    "                                lr = lr_temp\n",
    "                                state_dict = optimizer.state_dict()\n",
    "                                state_dict['param_groups'][0]['lr'] = lr\n",
    "                                optimizer.load_state_dict(state_dict)\n",
    "                            beta_temp = config.getfloat('Training', 'beta')\n",
    "                            if beta_temp > 0:\n",
    "                                beta = beta_temp\n",
    "                            stop_training = config.getboolean('Training', 'stop_training')\n",
    "                            guideOpen = config.getboolean('Training', 'guideOpen')\n",
    "                            batch_size = config.getint('Training', 'batch_size')\n",
    "                            \n",
    "                        # 设置保存路径和合法文件名\n",
    "                        save_path = \"./models\"\n",
    "                        os.makedirs(save_path, exist_ok=True)  # 确保路径存在\n",
    "                        current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')  # 使用合法字符\n",
    "                        currentNetFile = os.path.join(save_path, f'fb_rgb_v0_{current_time_str}.pth')\n",
    "                        torch.save(q_net.state_dict(), currentNetFile) # 保存模型\n",
    "                        last_save_time = current_time\n",
    "                    if current_time - last_print_time >= print_interval:\n",
    "                        last_print_time = current_time\n",
    "                        print(f\"{episode} | {min_interval_rewards:.3f} | {max_interval_rewards:.3f} | {max_reward_total:.3f} | {epsilon:.5f} | {max_score} | {steps_total} | {lr:.8e} | {update_step_interval} | {training_frequency} | {loss_threshold:.3f} | {beta:.5f} | {replay_buffer.size()}\")\n",
    "                        min_interval_rewards = np.inf\n",
    "                        max_interval_rewards = -np.inf\n",
    "                    # 更新 beta\n",
    "                    beta = min(1.0, beta + beta_increment)\n",
    "\n",
    "        rewards.append(total_reward)  # 确保 append 正常工作\n",
    "        if min_interval_rewards > total_reward:\n",
    "            min_interval_rewards = total_reward\n",
    "        # 重置噪声\n",
    "        q_net.reset_noise()\n",
    "        target_net.reset_noise()\n",
    "        if stop_training:\n",
    "            # 把配置文件的stop_training改为False\n",
    "            config['Training']['stop_training'] = 'False'\n",
    "            with open('config.ini', 'w') as configfile:\n",
    "                config.write(configfile)\n",
    "            break\n",
    "\n",
    "    return q_net, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置文件已创建并写入初始内容。\n",
      "Using device: cuda\n",
      "Episode | min interval reward | max interval reward | max_reward_total | Epsilon | max_score | steps_total | lr | update_step_interval | training_frequency | loss_threshold | beta | replay_buffer.size\n",
      "606 | 0.300 | 1.570 | 1.570 | 0.53658 | 2 | 54682 | 1.00000000e-06 | 100 | 0 | 0.900 | 0.86660 | 54663\n",
      "663 | 0.990 | 1.000 | 1.570 | 0.01000 | 2 | 60505 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 60486\n",
      "721 | 0.990 | 1.000 | 1.570 | 0.01000 | 2 | 66277 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 66264\n",
      "777 | 0.990 | 1.000 | 1.570 | 0.01000 | 2 | 71982 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 71963\n",
      "833 | 0.990 | 1.000 | 1.570 | 0.01000 | 2 | 77612 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 77593\n",
      "888 | 0.990 | 1.000 | 1.570 | 0.01000 | 2 | 83189 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 83170\n",
      "943 | 0.990 | 1.000 | 1.570 | 0.01000 | 2 | 88716 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 88697\n",
      "997 | 0.990 | 1.000 | 1.570 | 0.01000 | 2 | 94176 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 94157\n",
      "1050 | 0.990 | 1.020 | 1.570 | 0.01000 | 2 | 99520 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 99501\n",
      "1102 | 0.990 | 1.010 | 1.570 | 0.00913 | 2 | 104826 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1155 | 0.990 | 1.000 | 1.570 | 0.00816 | 2 | 110196 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1209 | 0.990 | 1.040 | 1.570 | 0.00720 | 2 | 115570 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1262 | 0.990 | 1.070 | 1.570 | 0.00623 | 2 | 120937 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1315 | 0.990 | 1.080 | 1.570 | 0.00527 | 2 | 126297 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1368 | 0.990 | 1.050 | 1.570 | 0.00430 | 2 | 131665 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1421 | 0.990 | 1.060 | 1.570 | 0.00334 | 2 | 137027 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1474 | 0.990 | 1.050 | 1.570 | 0.00237 | 2 | 142394 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1527 | 0.990 | 1.000 | 1.570 | 0.00140 | 2 | 147757 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1580 | 0.990 | 1.090 | 1.570 | 0.00100 | 2 | 153131 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1633 | 0.990 | 1.000 | 1.570 | 0.00100 | 2 | 158511 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1687 | 0.990 | 1.000 | 1.570 | 0.00100 | 2 | 163890 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1740 | 0.990 | 1.000 | 1.570 | 0.00100 | 2 | 169269 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1793 | 0.990 | 1.230 | 1.570 | 0.00100 | 2 | 174648 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1847 | 0.300 | 1.010 | 1.570 | 0.00100 | 2 | 180020 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1900 | 0.300 | 1.050 | 1.570 | 0.00100 | 2 | 185392 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1954 | 0.990 | 1.060 | 1.570 | 0.00100 | 2 | 190765 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2005 | 0.990 | 1.000 | 1.570 | 0.00100 | 2 | 195913 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2057 | 0.990 | 1.150 | 1.570 | 0.00100 | 2 | 201261 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2110 | 0.990 | 1.000 | 1.570 | 0.00100 | 2 | 206627 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2164 | 0.990 | 1.050 | 1.570 | 0.00100 | 2 | 211996 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2216 | 0.990 | 1.220 | 1.570 | 0.00100 | 2 | 217353 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2270 | 0.990 | 1.000 | 1.570 | 0.00100 | 2 | 222766 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2324 | 0.990 | 1.000 | 1.570 | 0.00100 | 2 | 228188 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2377 | 0.990 | 1.060 | 1.570 | 0.00100 | 2 | 233614 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2431 | 0.990 | 1.180 | 1.570 | 0.00100 | 2 | 239038 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2483 | 0.990 | 1.010 | 1.570 | 0.00100 | 2 | 244378 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2534 | 0.990 | 1.160 | 1.570 | 0.00100 | 2 | 249495 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2586 | 0.990 | 1.400 | 1.570 | 0.00096 | 2 | 254804 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2638 | 0.990 | 1.230 | 1.570 | 0.00091 | 2 | 260162 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2689 | 0.990 | 1.240 | 1.570 | 0.00086 | 2 | 265521 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2740 | 0.990 | 1.630 | 1.630 | 0.00081 | 2 | 270883 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2791 | 0.990 | 1.500 | 1.630 | 0.00076 | 2 | 276259 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2842 | 0.990 | 1.400 | 1.630 | 0.00072 | 2 | 281640 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2892 | 0.990 | 1.400 | 1.630 | 0.00067 | 2 | 287019 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2942 | 0.990 | 1.400 | 1.630 | 0.00062 | 2 | 292392 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2989 | 0.990 | 1.600 | 1.630 | 0.00057 | 2 | 297782 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3038 | 0.990 | 1.610 | 1.630 | 0.00052 | 2 | 303160 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3086 | 0.990 | 1.810 | 1.810 | 0.00047 | 2 | 308586 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3134 | 0.990 | 1.400 | 1.810 | 0.00042 | 2 | 314014 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3181 | 0.990 | 1.570 | 1.810 | 0.00038 | 2 | 319238 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3228 | 0.880 | 1.400 | 1.810 | 0.00033 | 2 | 324504 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3273 | 0.990 | 1.440 | 1.810 | 0.00028 | 2 | 329705 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3318 | 0.990 | 1.620 | 1.810 | 0.00024 | 2 | 334897 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3361 | 0.990 | 2.210 | 2.210 | 0.00019 | 3 | 340175 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3405 | 0.990 | 1.810 | 2.210 | 0.00014 | 3 | 345513 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3449 | 0.990 | 1.600 | 2.210 | 0.00010 | 3 | 350728 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3490 | 0.990 | 1.590 | 2.210 | 0.00009 | 3 | 355675 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3530 | 0.990 | 1.810 | 2.210 | 0.00008 | 3 | 360819 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3573 | 0.990 | 1.810 | 2.210 | 0.00007 | 3 | 365973 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3609 | 0.990 | 2.210 | 2.210 | 0.00006 | 3 | 370861 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3649 | 0.990 | 2.630 | 2.630 | 0.00005 | 4 | 376075 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3687 | 0.990 | 2.630 | 2.630 | 0.00004 | 4 | 381253 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3726 | 0.990 | 2.030 | 2.630 | 0.00003 | 4 | 386416 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3764 | 0.990 | 2.640 | 2.640 | 0.00002 | 4 | 391575 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3804 | 0.990 | 2.220 | 2.640 | 0.00001 | 4 | 396748 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3842 | 0.990 | 1.980 | 2.640 | 0.00000 | 4 | 401922 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3878 | 0.990 | 3.450 | 3.450 | 0.00000 | 6 | 407155 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3916 | 0.990 | 2.630 | 3.450 | 0.00000 | 6 | 412481 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3953 | 0.300 | 3.850 | 3.850 | 0.00000 | 7 | 417882 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3989 | 0.300 | 2.790 | 3.850 | 0.00000 | 7 | 423287 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4020 | 0.300 | 3.850 | 3.850 | 0.00000 | 7 | 428649 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4054 | 0.300 | 3.200 | 3.850 | 0.00000 | 7 | 434042 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4082 | 0.990 | 5.280 | 5.280 | 0.00000 | 11 | 439416 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4112 | 0.790 | 6.330 | 6.330 | 0.00000 | 13 | 444792 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4141 | 0.990 | 3.670 | 6.330 | 0.00000 | 13 | 450177 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4168 | 0.990 | 3.860 | 6.330 | 0.00000 | 13 | 455587 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4194 | 1.070 | 5.720 | 6.330 | 0.00000 | 13 | 460990 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4219 | 0.990 | 6.390 | 6.390 | 0.00000 | 13 | 466366 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4243 | 0.990 | 6.160 | 6.390 | 0.00000 | 13 | 471774 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4259 | 1.390 | 7.360 | 7.360 | 0.00000 | 16 | 477151 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4284 | 0.990 | 6.310 | 7.360 | 0.00000 | 16 | 482546 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4307 | 1.050 | 7.790 | 7.790 | 0.00000 | 17 | 487982 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4326 | 1.060 | 6.950 | 7.790 | 0.00000 | 17 | 493402 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4348 | 0.990 | 7.950 | 7.950 | 0.00000 | 17 | 498838 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4367 | 1.390 | 5.510 | 7.950 | 0.00000 | 17 | 504239 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4394 | 1.090 | 5.490 | 7.950 | 0.00000 | 17 | 509665 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4414 | 0.990 | 6.020 | 7.950 | 0.00000 | 17 | 515054 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4436 | 1.160 | 6.140 | 7.950 | 0.00000 | 17 | 520475 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4464 | 0.990 | 4.300 | 7.950 | 0.00000 | 17 | 525950 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4491 | 0.990 | 4.030 | 7.950 | 0.00000 | 17 | 531442 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4514 | 0.990 | 5.910 | 7.950 | 0.00000 | 17 | 536945 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4538 | 0.990 | 5.730 | 7.950 | 0.00000 | 17 | 542444 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4565 | 0.300 | 8.770 | 8.770 | 0.00000 | 19 | 547996 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4592 | 0.990 | 5.250 | 8.770 | 0.00000 | 19 | 553493 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4616 | 0.990 | 5.310 | 8.770 | 0.00000 | 19 | 558951 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4638 | 0.990 | 7.550 | 8.770 | 0.00000 | 19 | 564376 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4662 | 0.990 | 7.790 | 8.770 | 0.00000 | 19 | 569810 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4683 | 0.990 | 5.910 | 8.770 | 0.00000 | 19 | 575245 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4707 | 0.990 | 5.300 | 8.770 | 0.00000 | 19 | 580596 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4733 | 0.800 | 5.950 | 8.770 | 0.00000 | 19 | 585893 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4760 | 0.990 | 6.730 | 8.770 | 0.00000 | 19 | 591308 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4785 | 0.680 | 4.270 | 8.770 | 0.00000 | 19 | 596717 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4811 | 0.990 | 6.150 | 8.770 | 0.00000 | 19 | 602099 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4835 | 0.990 | 10.590 | 10.590 | 0.00000 | 24 | 607536 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4860 | 0.990 | 3.900 | 10.590 | 0.00000 | 24 | 612964 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4893 | 0.990 | 3.030 | 10.590 | 0.00000 | 24 | 618399 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4920 | 1.140 | 5.090 | 10.590 | 0.00000 | 24 | 623828 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4940 | 0.990 | 12.050 | 12.050 | 0.00000 | 27 | 629249 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4963 | 0.840 | 5.090 | 12.050 | 0.00000 | 27 | 634495 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4987 | 0.990 | 6.000 | 12.050 | 0.00000 | 27 | 639872 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5012 | 1.030 | 4.670 | 12.050 | 0.00000 | 27 | 645274 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "5043 | 1.050 | 5.090 | 12.050 | 0.00000 | 27 | 650575 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5073 | 0.990 | 4.670 | 12.050 | 0.00000 | 27 | 655800 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5100 | 0.990 | 3.850 | 12.050 | 0.00000 | 27 | 661198 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5128 | 1.060 | 3.920 | 12.050 | 0.00000 | 27 | 666608 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "5154 | 1.170 | 4.070 | 12.050 | 0.00000 | 27 | 672027 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "5182 | 0.990 | 3.850 | 12.050 | 0.00000 | 27 | 677448 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5205 | 1.140 | 5.090 | 12.050 | 0.00000 | 27 | 682784 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5231 | 0.300 | 8.180 | 12.050 | 0.00000 | 27 | 688120 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "5257 | 1.150 | 5.250 | 12.050 | 0.00000 | 27 | 693544 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5283 | 0.990 | 4.670 | 12.050 | 0.00000 | 27 | 698966 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5307 | 0.990 | 5.490 | 12.050 | 0.00000 | 27 | 704399 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5331 | 0.990 | 7.130 | 12.050 | 0.00000 | 27 | 709762 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5357 | 0.990 | 4.440 | 12.050 | 0.00000 | 27 | 714871 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5382 | 0.990 | 7.300 | 12.050 | 0.00000 | 27 | 720048 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5406 | 1.080 | 5.910 | 12.050 | 0.00000 | 27 | 725379 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5438 | 0.990 | 3.490 | 12.050 | 0.00000 | 27 | 730819 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5462 | 0.990 | 4.670 | 12.050 | 0.00000 | 27 | 736255 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5487 | 0.990 | 4.280 | 12.050 | 0.00000 | 27 | 741660 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5516 | 0.990 | 5.490 | 12.050 | 0.00000 | 27 | 746947 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5547 | 0.990 | 5.740 | 12.050 | 0.00000 | 27 | 752352 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5578 | 0.990 | 4.300 | 12.050 | 0.00000 | 27 | 757751 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5602 | 0.990 | 5.910 | 12.050 | 0.00000 | 27 | 763163 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5626 | 0.990 | 5.320 | 12.050 | 0.00000 | 27 | 768587 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5646 | 0.990 | 7.950 | 12.050 | 0.00000 | 27 | 774009 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5672 | 0.990 | 5.090 | 12.050 | 0.00000 | 27 | 779427 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5693 | 0.990 | 8.970 | 12.050 | 0.00000 | 27 | 784855 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5722 | 0.990 | 3.690 | 12.050 | 0.00000 | 27 | 790281 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5745 | 1.090 | 4.720 | 12.050 | 0.00000 | 27 | 795707 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5771 | 0.990 | 6.750 | 12.050 | 0.00000 | 27 | 801133 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5796 | 0.820 | 6.310 | 12.050 | 0.00000 | 27 | 806558 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5821 | 0.640 | 5.910 | 12.050 | 0.00000 | 27 | 811982 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5842 | 0.990 | 6.540 | 12.050 | 0.00000 | 27 | 817371 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5864 | 1.020 | 7.620 | 12.050 | 0.00000 | 27 | 822635 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5884 | 0.990 | 9.220 | 12.050 | 0.00000 | 27 | 828042 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5910 | 0.990 | 5.160 | 12.050 | 0.00000 | 27 | 833455 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5937 | 0.990 | 4.670 | 12.050 | 0.00000 | 27 | 838912 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5965 | 0.990 | 5.580 | 12.050 | 0.00000 | 27 | 844382 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5989 | 0.990 | 5.910 | 12.050 | 0.00000 | 27 | 849855 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6015 | 0.830 | 7.140 | 12.050 | 0.00000 | 27 | 855330 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6040 | 0.990 | 6.380 | 12.050 | 0.00000 | 27 | 860811 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6065 | 0.990 | 7.630 | 12.050 | 0.00000 | 27 | 866294 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6093 | 1.060 | 3.850 | 12.050 | 0.00000 | 27 | 871783 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6119 | 0.990 | 7.550 | 12.050 | 0.00000 | 27 | 877274 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6146 | 0.990 | 6.310 | 12.050 | 0.00000 | 27 | 882760 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6166 | 0.990 | 10.430 | 12.050 | 0.00000 | 27 | 888250 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6189 | 0.300 | 5.910 | 12.050 | 0.00000 | 27 | 893748 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6214 | 0.990 | 6.480 | 12.050 | 0.00000 | 27 | 899246 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6237 | 1.000 | 8.200 | 12.050 | 0.00000 | 27 | 904745 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6268 | 1.040 | 4.670 | 12.050 | 0.00000 | 27 | 910244 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6288 | 1.000 | 7.950 | 12.050 | 0.00000 | 27 | 915742 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6316 | 0.990 | 9.210 | 12.050 | 0.00000 | 27 | 921237 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6344 | 0.990 | 3.680 | 12.050 | 0.00000 | 27 | 926732 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6370 | 1.050 | 4.090 | 12.050 | 0.00000 | 27 | 932223 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6393 | 0.990 | 7.550 | 12.050 | 0.00000 | 27 | 937713 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6414 | 0.990 | 8.370 | 12.050 | 0.00000 | 27 | 943201 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6438 | 0.990 | 7.950 | 12.050 | 0.00000 | 27 | 948692 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6462 | 0.990 | 5.910 | 12.050 | 0.00000 | 27 | 954190 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6487 | 0.990 | 7.620 | 12.050 | 0.00000 | 27 | 959683 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6511 | 0.990 | 5.910 | 12.050 | 0.00000 | 27 | 965176 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6537 | 0.990 | 5.490 | 12.050 | 0.00000 | 27 | 970673 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6560 | 0.990 | 5.490 | 12.050 | 0.00000 | 27 | 976182 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6582 | 0.990 | 5.330 | 12.050 | 0.00000 | 27 | 981690 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6611 | 0.990 | 4.270 | 12.050 | 0.00000 | 27 | 987204 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6639 | 0.990 | 6.350 | 12.050 | 0.00000 | 27 | 992726 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6666 | 1.060 | 3.950 | 12.050 | 0.00000 | 27 | 998246 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6698 | 0.990 | 4.310 | 12.050 | 0.00000 | 27 | 1003763 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6724 | 1.010 | 4.780 | 12.050 | 0.00000 | 27 | 1009282 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6751 | 0.810 | 5.090 | 12.050 | 0.00000 | 27 | 1014798 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6774 | 1.030 | 10.590 | 12.050 | 0.00000 | 27 | 1020312 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6802 | 0.990 | 5.150 | 12.050 | 0.00000 | 27 | 1025828 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6828 | 0.760 | 7.950 | 12.050 | 0.00000 | 27 | 1031344 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6854 | 0.990 | 6.890 | 12.050 | 0.00000 | 27 | 1036859 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6875 | 1.000 | 6.540 | 12.050 | 0.00000 | 27 | 1042372 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6902 | 0.990 | 6.560 | 12.050 | 0.00000 | 27 | 1047885 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6928 | 1.210 | 3.850 | 12.050 | 0.00000 | 27 | 1053403 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6948 | 1.140 | 4.850 | 12.050 | 0.00000 | 27 | 1058919 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6978 | 0.990 | 5.090 | 12.050 | 0.00000 | 27 | 1064438 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7008 | 0.990 | 3.940 | 12.050 | 0.00000 | 27 | 1069960 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7028 | 0.990 | 12.290 | 12.290 | 0.00000 | 28 | 1075478 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7053 | 0.990 | 6.160 | 12.290 | 0.00000 | 28 | 1081004 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7082 | 1.050 | 5.090 | 12.290 | 0.00000 | 28 | 1086530 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7106 | 0.990 | 5.650 | 12.290 | 0.00000 | 28 | 1092051 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7127 | 0.990 | 9.380 | 12.290 | 0.00000 | 28 | 1097576 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7156 | 0.990 | 4.670 | 12.290 | 0.00000 | 28 | 1103103 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7180 | 0.990 | 6.080 | 12.290 | 0.00000 | 28 | 1108629 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7209 | 0.990 | 4.670 | 12.290 | 0.00000 | 28 | 1114155 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7240 | 0.990 | 3.450 | 12.290 | 0.00000 | 28 | 1119688 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7269 | 0.990 | 5.090 | 12.290 | 0.00000 | 28 | 1125219 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7293 | 1.190 | 4.510 | 12.290 | 0.00000 | 28 | 1130745 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7319 | 1.030 | 4.750 | 12.290 | 0.00000 | 28 | 1136259 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7350 | 0.750 | 6.560 | 12.290 | 0.00000 | 28 | 1141769 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7373 | 1.070 | 5.560 | 12.290 | 0.00000 | 28 | 1147267 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7399 | 0.990 | 5.920 | 12.290 | 0.00000 | 28 | 1152781 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7425 | 0.990 | 7.220 | 12.290 | 0.00000 | 28 | 1158293 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7451 | 0.990 | 6.140 | 12.290 | 0.00000 | 28 | 1163813 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7478 | 0.990 | 8.770 | 12.290 | 0.00000 | 28 | 1169337 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7507 | 0.990 | 4.770 | 12.290 | 0.00000 | 28 | 1174860 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7536 | 0.990 | 4.670 | 12.290 | 0.00000 | 28 | 1180382 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7563 | 1.060 | 5.490 | 12.290 | 0.00000 | 28 | 1185906 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7588 | 0.990 | 7.650 | 12.290 | 0.00000 | 28 | 1191430 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7617 | 0.990 | 5.490 | 12.290 | 0.00000 | 28 | 1196961 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7647 | 1.070 | 3.860 | 12.290 | 0.00000 | 28 | 1202491 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7674 | 0.990 | 5.910 | 12.290 | 0.00000 | 28 | 1208025 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7700 | 1.060 | 5.090 | 12.290 | 0.00000 | 28 | 1213552 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7723 | 0.990 | 5.740 | 12.290 | 0.00000 | 28 | 1219080 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7751 | 0.300 | 6.120 | 12.290 | 0.00000 | 28 | 1224608 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7776 | 0.990 | 9.620 | 12.290 | 0.00000 | 28 | 1230135 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7803 | 0.990 | 4.670 | 12.290 | 0.00000 | 28 | 1235662 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7834 | 0.990 | 7.130 | 12.290 | 0.00000 | 28 | 1241189 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7864 | 0.990 | 6.730 | 12.290 | 0.00000 | 28 | 1246717 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7891 | 0.990 | 4.720 | 12.290 | 0.00000 | 28 | 1252243 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7914 | 0.990 | 8.040 | 12.290 | 0.00000 | 28 | 1257770 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7948 | 0.990 | 4.270 | 12.290 | 0.00000 | 28 | 1263297 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7978 | 0.990 | 5.090 | 12.290 | 0.00000 | 28 | 1268827 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8007 | 0.990 | 4.290 | 12.290 | 0.00000 | 28 | 1274361 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8039 | 0.990 | 3.450 | 12.290 | 0.00000 | 28 | 1279904 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8064 | 0.990 | 6.160 | 12.290 | 0.00000 | 28 | 1285436 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8093 | 0.990 | 3.620 | 12.290 | 0.00000 | 28 | 1290978 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8125 | 0.990 | 4.320 | 12.290 | 0.00000 | 28 | 1296524 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8151 | 1.020 | 4.320 | 12.290 | 0.00000 | 28 | 1302064 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8179 | 0.990 | 6.730 | 12.290 | 0.00000 | 28 | 1307602 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8198 | 0.990 | 6.900 | 12.290 | 0.00000 | 28 | 1313142 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8220 | 0.990 | 10.830 | 12.290 | 0.00000 | 28 | 1318684 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8244 | 0.990 | 5.910 | 12.290 | 0.00000 | 28 | 1324221 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8269 | 0.990 | 6.730 | 12.290 | 0.00000 | 28 | 1329758 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8293 | 0.990 | 6.980 | 12.290 | 0.00000 | 28 | 1335296 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8319 | 0.990 | 4.670 | 12.290 | 0.00000 | 28 | 1340840 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8343 | 0.990 | 7.300 | 12.290 | 0.00000 | 28 | 1346386 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8374 | 0.990 | 4.870 | 12.290 | 0.00000 | 28 | 1351937 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8400 | 0.990 | 4.920 | 12.290 | 0.00000 | 28 | 1357491 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8427 | 0.990 | 5.090 | 12.290 | 0.00000 | 28 | 1363049 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8450 | 0.990 | 8.150 | 12.290 | 0.00000 | 28 | 1368609 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8472 | 0.990 | 6.900 | 12.290 | 0.00000 | 28 | 1374019 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8499 | 1.070 | 5.340 | 12.290 | 0.00000 | 28 | 1379507 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8526 | 1.020 | 5.580 | 12.290 | 0.00000 | 28 | 1385081 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8550 | 0.990 | 5.680 | 12.290 | 0.00000 | 28 | 1390642 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8573 | 1.150 | 8.770 | 12.290 | 0.00000 | 28 | 1396222 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8593 | 1.420 | 7.800 | 12.290 | 0.00000 | 28 | 1401826 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8622 | 0.990 | 3.850 | 12.290 | 0.00000 | 28 | 1407425 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8647 | 1.050 | 4.450 | 12.290 | 0.00000 | 28 | 1413026 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8675 | 0.990 | 6.000 | 12.290 | 0.00000 | 28 | 1418621 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8700 | 0.990 | 5.090 | 12.290 | 0.00000 | 28 | 1424143 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8728 | 1.020 | 4.520 | 12.290 | 0.00000 | 28 | 1429748 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8755 | 1.000 | 5.910 | 12.290 | 0.00000 | 28 | 1435333 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8780 | 0.820 | 11.260 | 12.290 | 0.00000 | 28 | 1440875 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8806 | 0.990 | 5.740 | 12.290 | 0.00000 | 28 | 1446432 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8833 | 0.990 | 6.730 | 12.290 | 0.00000 | 28 | 1452005 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8856 | 0.990 | 5.130 | 12.290 | 0.00000 | 28 | 1457555 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8889 | 0.990 | 4.280 | 12.290 | 0.00000 | 28 | 1463126 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8916 | 0.990 | 4.270 | 12.290 | 0.00000 | 28 | 1468559 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8945 | 0.990 | 4.710 | 12.290 | 0.00000 | 28 | 1473898 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import flappy_bird_gym\n",
    "import configparser\n",
    "\n",
    "# 创建ConfigParser对象\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# 添加配置项\n",
    "config['Training'] = {\n",
    "    'update_step_interval': '100',\n",
    "    'lr': '0.000001',\n",
    "    'delta_training_frequency': '0',\n",
    "    'delta_loss_threshold': '-0.1',\n",
    "    'loss_threshold' : '0.5',\n",
    "    'beta': '-0.1',\n",
    "    'guideopen': 'False',\n",
    "    'stop_training': 'False',\n",
    "    'batch_size': '256'\n",
    "}\n",
    "\n",
    "# 写入配置文件\n",
    "with open('config.ini', 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "\n",
    "print(\"配置文件已创建并写入初始内容。\")\n",
    "\n",
    "# 确保环境是 FlappyBird-v0\n",
    "env = gym.make(\"FlappyBird-rgb-v0\")\n",
    "import os\n",
    "import pygame\n",
    "\n",
    "# 将声音输出重定向到\"无声设备\"\n",
    "os.environ[\"SDL_AUDIODRIVER\"] = \"dummy\"  # 设置虚拟音频驱动\n",
    "pygame.mixer.quit()  # 重新初始化以应用设置\n",
    "\n",
    "# 训练网络\n",
    "q_net, rewards = train_rainbow_dqn(\n",
    "    env,\n",
    "    num_episodes=50000,\n",
    "    batch_size=256,\n",
    "    gamma=0.95,\n",
    "    epsilon_schedule=[(0, 1), (20000, 1), (60000, 0.01), (100000, 0.01), (150000, 0.001), (250000, 0.001), (350000, 0.0001), (400000, 0.0)],\n",
    "    lr=1e-6,\n",
    "    alpha=0.6,\n",
    "    beta_start=0.4,\n",
    "    beta_increment=1e-4,\n",
    "    number_of_states=4,\n",
    "    skip_frames=1,\n",
    "    atoms=51,\n",
    "    v_min=-0.02,\n",
    "    v_max=2.8,\n",
    "    modelFile = None\n",
    ")\n",
    "plot_dataList(rewards)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import flappy_bird_gym\n",
    "import pygame\n",
    "\n",
    "if os.path.exists(fileName):  # 判断是否存在fileName文件\n",
    "    env = flappy_bird_gym.make(\"FlappyBird-v0\")\n",
    "    input_shape = env.observation_space.shape[0]\n",
    "    output_dim = env.action_space.n\n",
    "    q_net = Dueling_NoisyDQN(input_shape, output_dim)\n",
    "    q_net.load_state_dict(torch.load(fileName, weights_only=True))\n",
    "    q_net.eval()\n",
    "    print(\"模型已加载\")\n",
    "    obs = env.reset()\n",
    "    bExit = False\n",
    "    current_score = 0\n",
    "    min_steps_between_flaps = 999999\n",
    "    steps_between_flaps = 0\n",
    "    while bExit == False:\n",
    "        obs = tuple(obs)\n",
    "        # Next action:\n",
    "        # (feed the observation to your agent here)\n",
    "        action = q_net(torch.tensor(obs, dtype=torch.float32).unsqueeze(0)).argmax().item()\n",
    "\n",
    "        # Processing:\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        steps_between_flaps += 1\n",
    "        if info['score'] > current_score:\n",
    "            current_score = info['score']\n",
    "            if steps_between_flaps < min_steps_between_flaps:\n",
    "                min_steps_between_flaps = steps_between_flaps\n",
    "            steps_between_flaps = 0\n",
    "        # Rendering the game:\n",
    "        # (remove this two lines during training)\n",
    "        env.render()\n",
    "        time.sleep(1 / 30)  # FPS\n",
    "\n",
    "        # 处理 pygame 事件队列，防止窗口卡死\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                env.close()\n",
    "                #exit()\n",
    "                bExit = True\n",
    "                done = True\n",
    "        \n",
    "        # Checking if the player is still alive\n",
    "        if done:\n",
    "            print(f\"score: {info['score']}\")\n",
    "            print(\"Game Over\")\n",
    "            steps_between_flaps = 0\n",
    "            obs = env.reset()\n",
    "\n",
    "    env.close()\n",
    "    print(f\"min_steps_between_flaps: {min_steps_between_flaps}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
