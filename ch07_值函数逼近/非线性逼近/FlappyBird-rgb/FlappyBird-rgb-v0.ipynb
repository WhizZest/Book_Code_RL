{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "# Q网络定义\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 经验回放池\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        states, actions, rewards, next_states, dones = zip(*random.sample(self.buffer, batch_size))\n",
    "        return (\n",
    "            torch.tensor(np.stack(states), dtype=torch.float32),\n",
    "            torch.tensor(actions, dtype=torch.int64),\n",
    "            torch.tensor(rewards, dtype=torch.float32),\n",
    "            torch.tensor(np.stack(next_states), dtype=torch.float32),\n",
    "            torch.tensor(dones, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_dataList(rewards, xStart=0):\n",
    "    # 设置图像的宽度为 12 英寸\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.plot(range(xStart, len(rewards) + xStart), rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Total Reward vs Episode')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.V = nn.Linear(128, 1)\n",
    "        self.A = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        V = self.V(x)\n",
    "        A = self.A(x)\n",
    "        Q = V + (A - A.mean(dim=1, keepdim=True))\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6):\n",
    "        \"\"\"\n",
    "        capacity: 缓冲区容量\n",
    "        alpha: 优先级比例，0表示完全随机采样，1表示完全按优先级采样\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.priorities = np.zeros((capacity,), dtype=np.float32)\n",
    "        self.position = 0\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"添加新经验，优先级初始化为最大值以确保被采样\"\"\"\n",
    "        max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append((state, action, reward, next_state, done))\n",
    "        else:\n",
    "            self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.priorities[self.position] = max_priority\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        \"\"\"\n",
    "        采样带优先级的批次数据\n",
    "        beta: 重要性采样的偏置修正参数\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == self.capacity:\n",
    "            priorities = self.priorities\n",
    "        else:\n",
    "            priorities = self.priorities[:self.position]\n",
    "        \n",
    "        # 根据优先级分布计算采样概率\n",
    "        probs = priorities ** self.alpha\n",
    "        probs /= probs.sum()\n",
    "\n",
    "        # 按照概率采样\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[idx] for idx in indices]\n",
    "\n",
    "        # 计算重要性采样权重\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()\n",
    "\n",
    "        # 解包样本\n",
    "        states, actions, rewards, next_states, dones = zip(*samples)\n",
    "        return (\n",
    "            torch.tensor(np.stack(states), dtype=torch.float32),\n",
    "            torch.tensor(actions, dtype=torch.int64),\n",
    "            torch.tensor(rewards, dtype=torch.float32),\n",
    "            torch.tensor(np.stack(next_states), dtype=torch.float32),\n",
    "            torch.tensor(dones, dtype=torch.float32),\n",
    "            torch.tensor(weights, dtype=torch.float32),\n",
    "            indices,\n",
    "        )\n",
    "\n",
    "    def update_priorities(self, indices, priorities):\n",
    "        \"\"\"根据新的 TD Error 更新优先级\"\"\"\n",
    "        self.priorities[indices] = priorities\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, std_init=0.5):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        # 可训练参数\n",
    "        self.weight_mu = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.bias_mu = nn.Parameter(torch.empty(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.empty(out_features))\n",
    "\n",
    "        # 非参数化噪声\n",
    "        self.register_buffer(\"weight_epsilon\", torch.empty(out_features, in_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.empty(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # 初始化可训练参数\n",
    "        bound = 1 / self.in_features ** 0.5\n",
    "        self.weight_mu.data.uniform_(-bound, bound)\n",
    "        self.weight_sigma.data.fill_(self.std_init / (self.in_features ** 0.5))\n",
    "        self.bias_mu.data.uniform_(-bound, bound)\n",
    "        self.bias_sigma.data.fill_(self.std_init / (self.in_features ** 0.5))\n",
    "\n",
    "    def reset_noise(self):\n",
    "        # 采样噪声\n",
    "        self.weight_epsilon.normal_()\n",
    "        self.bias_epsilon.normal_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            weight = self.weight_mu + self.weight_sigma * self.weight_epsilon\n",
    "            bias = self.bias_mu + self.bias_sigma * self.bias_epsilon\n",
    "        else:\n",
    "            weight = self.weight_mu\n",
    "            bias = self.bias_mu\n",
    "        return torch.nn.functional.linear(x, weight, bias)\n",
    "\n",
    "class Dueling_NoisyDQN(nn.Module):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super(Dueling_NoisyDQN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),  # (C, H, W) -> Conv,输出：32@20x20\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), # 输出：64@9x9\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1), # 输出：64@7x7\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 计算卷积后的特征图的尺寸\n",
    "        conv_output_size = self._get_conv_output_size(input_shape)\n",
    "\n",
    "        # Noisy 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            NoisyLinear(conv_output_size, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Dueling 分支\n",
    "        self.V = NoisyLinear(512, 1)            # 状态价值分支\n",
    "        self.A = NoisyLinear(512, output_dim)   # 优势值分支\n",
    "\n",
    "    def _get_conv_output_size(self, shape):\n",
    "        x = torch.zeros(1, *shape)  # 临时张量用于计算\n",
    "        x = self.conv(x)\n",
    "        return int(torch.flatten(x, 1).size(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)  # 展平为向量\n",
    "        x = self.fc(x)\n",
    "\n",
    "        V = self.V(x)\n",
    "        A = self.A(x)\n",
    "        Q = V + (A - A.mean(dim=1, keepdim=True))\n",
    "        return Q\n",
    "\n",
    "    def reset_noise(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, NoisyLinear):\n",
    "                m.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepPrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6, n_step=3, gamma=0.99):\n",
    "        \"\"\"\n",
    "        capacity: 缓冲区容量\n",
    "        alpha: 优先级比例，0表示完全随机采样，1表示完全按优先级采样\n",
    "        n_step: 多步时间跨度\n",
    "        gamma: 折扣因子\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.priorities = np.zeros((capacity,), dtype=np.float32)\n",
    "        self.position = 0\n",
    "        self.alpha = alpha\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # 用于多步存储的临时队列\n",
    "        self.n_step_queue = []\n",
    "\n",
    "    def _get_n_step_info(self):\n",
    "        \"\"\"从 n_step_queue 计算 n 步累计奖励和目标状态\"\"\"\n",
    "        R = 0\n",
    "        # 实际队列长度可能小于 n_step\n",
    "        n_step = len(self.n_step_queue)\n",
    "        for idx, (_, _, reward, _, _) in enumerate(self.n_step_queue):\n",
    "            R += (self.gamma ** idx) * reward\n",
    "        state, action, _, next_state, done = self.n_step_queue[0]\n",
    "        final_next_state, final_done = self.n_step_queue[-1][3], self.n_step_queue[-1][4]\n",
    "        return (state, action, R, final_next_state, final_done, n_step)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        添加新经验。\n",
    "        使用 n_step_queue 缓存多步数据，只有在积累到 n 步时才存入 buffer。\n",
    "        在轨迹结束时处理剩余的队列。\n",
    "        \"\"\"\n",
    "        self.n_step_queue.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        # 如果 n_step_queue 满了，处理一个完整的 n-step 转移\n",
    "        if len(self.n_step_queue) == self.n_step:\n",
    "            n_step_transition = self._get_n_step_info()\n",
    "            max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "            if len(self.buffer) < self.capacity:\n",
    "                self.buffer.append(n_step_transition)\n",
    "            else:\n",
    "                self.buffer[self.position] = n_step_transition\n",
    "            self.priorities[self.position] = max_priority\n",
    "            self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "            # 移除队列的第一个元素\n",
    "            self.n_step_queue.pop(0)\n",
    "\n",
    "        # 如果 done=True，处理剩余队列中的短步转移\n",
    "        if done:\n",
    "            while self.n_step_queue:\n",
    "                n_step_transition = self._get_n_step_info()\n",
    "                max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "                if len(self.buffer) < self.capacity:\n",
    "                    self.buffer.append(n_step_transition)\n",
    "                else:\n",
    "                    self.buffer[self.position] = n_step_transition\n",
    "                self.priorities[self.position] = max_priority\n",
    "                self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "                # 移除队列的第一个元素\n",
    "                self.n_step_queue.pop(0)\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4, device='cpu'):\n",
    "        \"\"\"\n",
    "        采样带优先级的批次数据。\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == self.capacity:\n",
    "            priorities = self.priorities\n",
    "        else:\n",
    "            priorities = self.priorities[:self.position]\n",
    "\n",
    "        # 根据优先级分布计算采样概率\n",
    "        probs = priorities ** self.alpha\n",
    "        probs /= (probs.sum() + 1e-8)\n",
    "\n",
    "        # 按照概率采样\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[idx] for idx in indices]\n",
    "\n",
    "        # 计算重要性采样权重\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()\n",
    "\n",
    "        # 解包样本\n",
    "        states, actions, rewards, next_states, dones, n_steps = zip(*samples)\n",
    "        return (\n",
    "            torch.tensor(np.stack(states), dtype=torch.float32).to(device),\n",
    "            torch.tensor(actions, dtype=torch.int64).to(device),\n",
    "            torch.tensor(rewards, dtype=torch.float32).to(device),\n",
    "            torch.tensor(np.stack(next_states), dtype=torch.float32).to(device),\n",
    "            torch.tensor(dones, dtype=torch.float32).to(device),\n",
    "            torch.tensor(weights, dtype=torch.float32).to(device),\n",
    "            torch.tensor(n_steps, dtype=torch.int64).to(device),\n",
    "            indices,\n",
    "        )\n",
    "\n",
    "    def update_priorities(self, indices, priorities):\n",
    "        \"\"\"根据新的 TD Error 更新优先级\"\"\"\n",
    "        self.priorities[indices] = priorities\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def current_queue_size(self):\n",
    "        return len(self.n_step_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess_image(frame, method='binarize'):\n",
    "    # 预处理图像：背景黑化(颜色值为200的像素点设为黑色)、灰度化、裁剪、缩放、二值化\n",
    "    frame[frame == 200] = 0\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_cropped = frame_gray[:, :420]  # 裁剪掉地面部分\n",
    "    frame_resize = cv2.resize(frame_cropped, (84, 84))\n",
    "    if method == 'binarize':\n",
    "        processed_frame = cv2.threshold(frame_resize, 1, 255, cv2.THRESH_BINARY)[1]\n",
    "    else:\n",
    "        # 归一化到 [0, 1]\n",
    "        processed_frame = frame_resize / 255.0\n",
    "    return processed_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.3 (SDL 2.0.16, Python 3.8.20)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pygame\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import configparser\n",
    "\n",
    "bestScoreFileName = 'flappy_bird_v0_model_best_score.pth'\n",
    "\n",
    "def train_dueling_dqn_noise_MultiStep_PER(env, num_episodes=500, batch_size=64, gamma=0.99, \n",
    "                                          epsilon_schedule=[(0, 1.0), (20000, 0.1), (700000, 0.01), (1040000, 0.001), (1720000, 0.0001), (2060000, 0.0)], \n",
    "                                          lr=1e-3, alpha=0.6, beta_start=0.4, beta_increment=1e-4, \n",
    "                                          number_of_states=4, preprocessHeight=84, preprocessWidth=84, skip_frames=1,\n",
    "                                          modelFile = None):\n",
    "    # 新的状态维度为原始状态维度的 number_of_states 倍\n",
    "    input_shape = (number_of_states, preprocessHeight, preprocessWidth)\n",
    "    output_dim = env.action_space.n\n",
    "\n",
    "    # 检查是否有GPU可用\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    q_net = Dueling_NoisyDQN(input_shape, output_dim).to(device)\n",
    "    # 判断是否存在modelFile文件\n",
    "    if modelFile and os.path.exists(modelFile):\n",
    "        q_net.load_state_dict(torch.load(modelFile, weights_only=True, map_location=device))\n",
    "        print(\"模型已加载\")\n",
    "    q_net.train() # 设置为训练模式，需要通过训练更新参数，该行代码可以省略，因为默认就是训练模式\n",
    "    target_net = Dueling_NoisyDQN(input_shape, output_dim).to(device)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "    target_net.eval() # 设置为评估模式，不需要通过训练更新参数，更新时只需要复制q_net的参数\n",
    "\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=lr)\n",
    "    gamma = gamma ** skip_frames  # 跳帧处理\n",
    "    replay_buffer_capacity = 100000\n",
    "    replay_buffer = MultiStepPrioritizedReplayBuffer(capacity=replay_buffer_capacity, alpha=alpha, n_step=20, gamma=gamma)\n",
    "    epsilon = epsilon_schedule[0][1]\n",
    "    beta = beta_start\n",
    "    rewards = []  # 确保它是一个列表\n",
    "    max_reward_total = -np.inf\n",
    "    max_interval_rewards = -np.inf\n",
    "    min_interval_rewards = np.inf\n",
    "    max_score = 0\n",
    "    score_nearest = deque(maxlen=5)\n",
    "    max_step_count = 0\n",
    "    update_step_count = 0\n",
    "    update_step_interval = 200\n",
    "    print_interval = 300  # 间隔（单位：秒）\n",
    "    # 记录训练开始的时间\n",
    "    last_save_time = time.time()\n",
    "    last_print_time = last_save_time\n",
    "    stop_training = False\n",
    "    steps_Interval = 1000\n",
    "    steps_perInterval = 0\n",
    "    steps_total = 0\n",
    "    loss_perInterval = 0\n",
    "    q_value_perInterval = 0\n",
    "    # 获取当前时间戳\n",
    "    current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    csv_file = f'dueling_dqn_noise_MultiStep_PER_{current_time_str}.csv'\n",
    "\n",
    "    # 创建表格文件，列名分别为：总步数、epsilon、平均损失、平均Q值\n",
    "    with open(csv_file, 'w') as f:\n",
    "        f.write('Time,episode,Steps,epsilon,loss,Q_value,max_reward_total,max_score,max_score_nearest,min_score_nearest,avg_score_nearest,max_reward_nearest,min_reward_nearest,avg_reward_nearest\\n')\n",
    "        f.close()\n",
    "    ratio_schedule = []\n",
    "    for i in range(len(epsilon_schedule) - 1):\n",
    "        start_step, start_epsilon = epsilon_schedule[i]\n",
    "        end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "        ratio = (end_epsilon - start_epsilon) / (end_step - start_step)\n",
    "        ratio_schedule.append(ratio)\n",
    "    \n",
    "    print(f\"Episode | min interval reward | max interval reward | max_reward_total | Epsilon | max_score | steps_total | lr | update_step_interval | beta | replay_buffer.size\")\n",
    "    for episode in range(num_episodes):\n",
    "        raw_state = env.reset()  # 返回 numpy.ndarray\n",
    "        processed_frame = preprocess_image(raw_state)\n",
    "        state_queue = deque([processed_frame.copy() for _ in range(number_of_states)], maxlen=number_of_states)  # 初始化队列，初始状态填充队列\n",
    "        state = np.array(state_queue)\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        step_count = 0\n",
    "        reward_perSkip = 0\n",
    "        score = 0\n",
    "\n",
    "        while not done:  # 每个 episode 的最大步数\n",
    "            # 根据多段线性衰减策略计算 epsilon\n",
    "            for i in range(len(epsilon_schedule) - 1):\n",
    "                start_step, start_epsilon = epsilon_schedule[i]\n",
    "                end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "                if start_step <= steps_total / skip_frames < end_step:\n",
    "                    # 在当前阶段内进行线性插值\n",
    "                    ratio = ratio_schedule[i]\n",
    "                    epsilon = max(start_epsilon + ratio * (steps_total / skip_frames - start_step), end_epsilon)\n",
    "                elif steps_total / skip_frames >= end_step and i == len(epsilon_schedule) - 2:\n",
    "                    epsilon = end_epsilon\n",
    "            # 跳帧处理\n",
    "            if step_count % skip_frames == 0:\n",
    "                # ε-贪婪策略\n",
    "                if random.random() < epsilon:\n",
    "                    # 根据概率决定采样\n",
    "                    if random.random() < 0.07 * skip_frames:\n",
    "                        action = 1\n",
    "                    else:\n",
    "                        action = 0\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        action = q_net(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)).argmax().item()\n",
    "                action_perSkip = action\n",
    "            else:\n",
    "                action = 0\n",
    "\n",
    "            # 执行动作\n",
    "            next_raw_state, reward, done, info = env.step(action)\n",
    "            step_count += 1\n",
    "            steps_total += 1\n",
    "            bSkip = True\n",
    "            if step_count % skip_frames == 0:\n",
    "                bSkip = False\n",
    "                reward_perSkip = 0\n",
    "            if max_step_count < step_count:\n",
    "                max_step_count = step_count\n",
    "            raw_state = next_raw_state\n",
    "            if done:\n",
    "                bSkip = False\n",
    "            # 更新状态队列\n",
    "            processed_frame = preprocess_image(raw_state)\n",
    "            state_queue.append(processed_frame)\n",
    "            next_state = np.array(state_queue)\n",
    "            reward = reward # 缩放奖励\n",
    "            # 得分\n",
    "            bScore = False\n",
    "            if info['score'] > score:\n",
    "                reward += 1  # 奖励增加\n",
    "                score = info['score']\n",
    "                bScore = True\n",
    "            if info['score'] > max_score:\n",
    "                max_score = info['score']\n",
    "                if max_score > 100:\n",
    "                    torch.save(q_net.state_dict(), bestScoreFileName) # 保存模型\n",
    "            if done:\n",
    "                reward -= 0.5  # 惩罚\n",
    "            reward_perSkip += reward\n",
    "            if bSkip == False:\n",
    "                replay_buffer.add(state, action_perSkip, reward_perSkip, next_state, done)\n",
    "                state = next_state\n",
    "            total_reward += reward\n",
    "            if total_reward > max_reward_total:\n",
    "                max_reward_total = total_reward\n",
    "            if max_interval_rewards < total_reward:\n",
    "                max_interval_rewards = total_reward\n",
    "\n",
    "            # 经验回放训练\n",
    "            if replay_buffer.size() >= replay_buffer_capacity * 0.1 and bSkip == False:\n",
    "                # 从优先级缓冲区中采样\n",
    "                states, actions, rewards_batch, next_states, dones, weights, n_step_batch, indices = replay_buffer.sample(batch_size, beta, device)\n",
    "\n",
    "                q_values = q_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "                with torch.no_grad():\n",
    "                    q_value_perInterval += q_values.mean().item() / steps_Interval\n",
    "                    best_actions = q_net(next_states).argmax(1)  # 使用当前网络选择最大Q值的动作\n",
    "                    target_q_values = rewards_batch + (gamma ** n_step_batch) * (1 - dones) * target_net(next_states).gather(1, best_actions.unsqueeze(1)).squeeze(1)\n",
    "                # 计算 TD Error\n",
    "                td_errors = target_q_values - q_values\n",
    "                loss = (weights * td_errors.pow(2)).mean()\n",
    "                loss_perInterval += loss.item() / steps_Interval\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 更新优先级\n",
    "                priorities = td_errors.abs().detach().cpu().numpy()\n",
    "                replay_buffer.update_priorities(indices, priorities)\n",
    "                update_step_count += 1\n",
    "                steps_perInterval += 1\n",
    "            \n",
    "                # 更新目标网络\n",
    "                if update_step_count >= update_step_interval:\n",
    "                    update_step_count = 0\n",
    "                    target_net.load_state_dict(q_net.state_dict()) # 将q_net的参数复制到target_net中\n",
    "                if steps_perInterval >= steps_Interval:\n",
    "                    # 计算rewards的最近5个数据的最大、最小、平均值\n",
    "                    max_reward_nearest = max(rewards[len(rewards) - 5:])\n",
    "                    min_reward_nearest = min(rewards[len(rewards) - 5:])\n",
    "                    avg_reward_nearest = sum(rewards[len(rewards) - 5:]) / 5\n",
    "                    # 计算score_nearest的最大、最小、平均值\n",
    "                    score_nearest_arr = np.array(score_nearest)\n",
    "                    max_score_nearest = score_nearest_arr.max()\n",
    "                    min_score_nearest = score_nearest_arr.min()\n",
    "                    avg_score_nearest = score_nearest_arr.mean()\n",
    "                    # 追加数据到 CSV 文件\n",
    "                    with open(csv_file, 'a') as f:\n",
    "                        current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        f.write(f'{current_time_str},{episode},{steps_total},{epsilon},{loss_perInterval},{q_value_perInterval},{max_reward_total},{max_score},{max_score_nearest},{min_score_nearest},{avg_score_nearest},{max_reward_nearest},{min_reward_nearest},{avg_reward_nearest}\\n')\n",
    "                    steps_perInterval = 0\n",
    "                    loss_perInterval = 0\n",
    "                    q_value_perInterval = 0\n",
    "                # 检查时间间隔\n",
    "                current_time = time.time()\n",
    "                if current_time - last_save_time > 60:\n",
    "                    # 读取配置文件\n",
    "                    config = configparser.ConfigParser()\n",
    "                    if config.read('config.ini'):\n",
    "                        update_step_interval = config.getint('Training', 'update_step_interval')\n",
    "                        lr_temp = config.getfloat('Training', 'lr')\n",
    "                        if lr_temp > 0:\n",
    "                            lr = lr_temp\n",
    "                            state_dict = optimizer.state_dict()\n",
    "                            state_dict['param_groups'][0]['lr'] = lr\n",
    "                            optimizer.load_state_dict(state_dict)\n",
    "                        beta_temp = config.getfloat('Training', 'beta')\n",
    "                        if beta_temp > 0:\n",
    "                            beta = beta_temp\n",
    "                        stop_training = config.getboolean('Training', 'stop_training')\n",
    "                        batch_size = config.getint('Training', 'batch_size')\n",
    "                        \n",
    "                    # 设置保存路径和合法文件名\n",
    "                    save_path = \"./models\"\n",
    "                    os.makedirs(save_path, exist_ok=True)  # 确保路径存在\n",
    "                    current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')  # 使用合法字符\n",
    "                    currentNetFile = os.path.join(save_path, f'fb_rgb_v0_{current_time_str}.pth')\n",
    "                    torch.save(q_net.state_dict(), currentNetFile) # 保存模型\n",
    "                    last_save_time = current_time\n",
    "                if current_time - last_print_time >= print_interval:\n",
    "                    last_print_time = current_time\n",
    "                    print(f\"{episode} | {min_interval_rewards:.3f} | {max_interval_rewards:.3f} | {max_reward_total:.3f} | {epsilon:.5f} | {max_score} | {steps_total} | {lr:.8e} | {update_step_interval} | {beta:.5f} | {replay_buffer.size()}\")\n",
    "                    min_interval_rewards = np.inf\n",
    "                    max_interval_rewards = -np.inf\n",
    "                # 更新 beta\n",
    "                beta = min(1.0, beta + beta_increment)\n",
    "\n",
    "        rewards.append(total_reward)  # 确保 append 正常工作\n",
    "        if min_interval_rewards > total_reward:\n",
    "            min_interval_rewards = total_reward\n",
    "        score_nearest.append(score)\n",
    "        # 重置噪声\n",
    "        q_net.reset_noise()\n",
    "        target_net.reset_noise()\n",
    "        if stop_training:\n",
    "            # 把配置文件的stop_training改为False\n",
    "            config['Training']['stop_training'] = 'False'\n",
    "            with open('config.ini', 'w') as configfile:\n",
    "                config.write(configfile)\n",
    "            break\n",
    "\n",
    "    return q_net, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Dueling_Noisy_DistributionalDQN(nn.Module):\n",
    "    def __init__(self, input_shape, output_dim, num_atoms=51):\n",
    "        super(Dueling_Noisy_DistributionalDQN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),  # (C, H, W) -> Conv,输出：32@20x20\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), # 输出：64@9x9\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1), # 输出：64@7x7\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 计算卷积后的特征图的尺寸\n",
    "        conv_output_size = self._get_conv_output_size(input_shape)\n",
    "\n",
    "        # Noisy 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            NoisyLinear(conv_output_size, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Dueling 分支\n",
    "        self.V = NoisyLinear(512, num_atoms)            # 状态价值分支\n",
    "        self.A = NoisyLinear(512, output_dim * num_atoms)   # 优势值分支\n",
    "        self.num_atoms = num_atoms\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def _get_conv_output_size(self, shape):\n",
    "        x = torch.zeros(1, *shape)  # 临时张量用于计算\n",
    "        x = self.conv(x)\n",
    "        return int(torch.flatten(x, 1).size(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)  # 展平为向量\n",
    "        x = self.fc(x)\n",
    "\n",
    "        V = self.V(x).view(-1, 1, self.num_atoms)\n",
    "        A = self.A(x).view(-1, self.output_dim, self.num_atoms)\n",
    "        Q = V + (A - A.mean(dim=1, keepdim=True))\n",
    "        Q_prob = F.softmax(Q, dim=2) # 将 Q 值转换为概率分布\n",
    "        return Q_prob\n",
    "\n",
    "    def reset_noise(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, NoisyLinear):\n",
    "                m.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_distribution(next_dist, rewards, dones, gammas, atoms, v_min, v_max, delta_z, support):\n",
    "    \"\"\"\n",
    "    投影 Bellman 更新后的分布到支持点。\n",
    "    \"\"\"\n",
    "    #delta_z = (v_max - v_min) / (atoms - 1)\n",
    "    #support = torch.linspace(v_min, v_max, atoms).to(next_dist.device)  # Shape: (atoms,)\n",
    "    \n",
    "    batch_size = rewards.size(0)\n",
    "    next_support = rewards.unsqueeze(1) + gammas.unsqueeze(1) * support.unsqueeze(0) * (1 - dones.unsqueeze(1))  # Shape: (batch_size, atoms)\n",
    "    next_support = next_support.clamp(v_min, v_max)  # 限制范围\n",
    "\n",
    "    b = (next_support - v_min) / delta_z  # Shape: (batch_size, atoms)\n",
    "    l = b.floor().long()  # Shape: (batch_size, atoms)\n",
    "    u = b.ceil().long()  # Shape: (batch_size, atoms)\n",
    "    \n",
    "    # 修正索引的范围，确保不越界\n",
    "    l = l.clamp(0, atoms - 1)\n",
    "    u = u.clamp(0, atoms - 1)\n",
    "    \n",
    "    proj_dist = torch.zeros(batch_size, atoms).to(next_dist.device)  # Shape: (batch_size, atoms)\n",
    "\n",
    "    for i in range(atoms):  # 遍历每个支持点\n",
    "        # 注意：next_dist[:, i] 实际是 batch_size 的第 i 列 (shape: [batch_size])\n",
    "        # next_dist 应被广播以匹配 l 和 u 的维度\n",
    "        weight_left = (u[:, i] - b[:, i]).unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "        weight_right = (b[:, i] - l[:, i]).unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "        \n",
    "        proj_dist.scatter_add_(1, l[:, i].unsqueeze(1), next_dist[:, i].unsqueeze(1) * weight_left)\n",
    "        proj_dist.scatter_add_(1, u[:, i].unsqueeze(1), next_dist[:, i].unsqueeze(1) * weight_right)\n",
    "\n",
    "    # 归一化分布\n",
    "    proj_dist /= proj_dist.sum(dim=1, keepdim=True) + 1e-8  # 防止除零\n",
    "    return proj_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rainbow_dqn(env, num_episodes=500, batch_size=64, gamma=0.99, \n",
    "                    epsilon_schedule=[(0, 1.0), (20000, 0.1), (700000, 0.01), (1040000, 0.001), (1720000, 0.0001), (2060000, 0.0)], \n",
    "                    lr=1e-3, alpha=0.6, beta_start=0.4, beta_increment=1e-4, \n",
    "                    number_of_states=4, preprocessHeight=84, preprocessWidth=84, skip_frames=1,\n",
    "                    atoms=51, v_min=-10, v_max=10,\n",
    "                    modelFile = None):\n",
    "    # 新的状态维度为原始状态维度的 number_of_states 倍\n",
    "    input_shape = (number_of_states, preprocessHeight, preprocessWidth)\n",
    "    output_dim = env.action_space.n\n",
    "\n",
    "    # 检查是否有GPU可用\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    q_net = Dueling_Noisy_DistributionalDQN(input_shape, output_dim, atoms).to(device)\n",
    "    # 判断是否存在modelFile文件\n",
    "    if modelFile and os.path.exists(modelFile):\n",
    "        q_net.load_state_dict(torch.load(modelFile, weights_only=True, map_location=device))\n",
    "        print(\"模型已加载\")\n",
    "    q_net.train() # 设置为训练模式，需要通过训练更新参数，该行代码可以省略，因为默认就是训练模式\n",
    "    target_net = Dueling_Noisy_DistributionalDQN(input_shape, output_dim, atoms).to(device)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "    target_net.eval() # 设置为评估模式，不需要通过训练更新参数，更新时只需要复制q_net的参数\n",
    "\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=lr)\n",
    "    gamma = gamma ** skip_frames  # 跳帧处理\n",
    "    replay_buffer_capacity = 100000\n",
    "    replay_buffer = MultiStepPrioritizedReplayBuffer(capacity=replay_buffer_capacity, alpha=alpha, n_step=20, gamma=gamma)\n",
    "    delta_z = (v_max - v_min) / (atoms - 1)\n",
    "    supports = torch.linspace(v_min, v_max, atoms).to(device)\n",
    "    epsilon = epsilon_schedule[0][1]\n",
    "    beta = beta_start\n",
    "    rewards = []  # 确保它是一个列表\n",
    "    max_reward_total = -np.inf\n",
    "    max_interval_rewards = -np.inf\n",
    "    min_interval_rewards = np.inf\n",
    "    max_score = 0\n",
    "    max_step_count = 0\n",
    "    update_step_count = 0\n",
    "    update_step_interval = 200\n",
    "    print_interval = 300  # 间隔（单位：秒）\n",
    "    # 记录训练开始的时间\n",
    "    last_save_time = time.time()\n",
    "    last_print_time = last_save_time\n",
    "    stop_training = False\n",
    "    steps_Interval = 1000\n",
    "    steps_perInterval = 0\n",
    "    steps_total = 0\n",
    "    loss_perInterval = 0\n",
    "    q_value_perInterval = 0\n",
    "    # 获取当前时间戳\n",
    "    current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    csv_file = f'dueling_dqn_noise_MultiStep_PER_{current_time_str}.csv'\n",
    "\n",
    "    # 创建表格文件，列名分别为：总步数、epsilon、平均损失、平均Q值\n",
    "    with open(csv_file, 'w') as f:\n",
    "        f.write('Time,episode,Steps,epsilon,loss,Q_value\\n')\n",
    "        f.close()\n",
    "    ratio_schedule = []\n",
    "    for i in range(len(epsilon_schedule) - 1):\n",
    "        start_step, start_epsilon = epsilon_schedule[i]\n",
    "        end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "        ratio = (end_epsilon - start_epsilon) / (end_step - start_step)\n",
    "        ratio_schedule.append(ratio)\n",
    "    \n",
    "    print(f\"Episode | min interval reward | max interval reward | max_reward_total | Epsilon | max_score | steps_total | lr | update_step_interval | beta | replay_buffer.size\")\n",
    "    for episode in range(num_episodes):\n",
    "        raw_state = env.reset()  # 返回 numpy.ndarray\n",
    "        processed_frame = preprocess_image(raw_state)\n",
    "        state_queue = deque([processed_frame.copy() for _ in range(number_of_states)], maxlen=number_of_states)  # 初始化队列，初始状态填充队列\n",
    "        state = np.array(state_queue)\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        step_count = 0\n",
    "        reward_perSkip = 0\n",
    "        score = 0\n",
    "\n",
    "        while not done:  # 每个 episode 的最大步数\n",
    "            # 根据多段线性衰减策略计算 epsilon\n",
    "            for i in range(len(epsilon_schedule) - 1):\n",
    "                start_step, start_epsilon = epsilon_schedule[i]\n",
    "                end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "                if start_step <= steps_total / skip_frames < end_step:\n",
    "                    # 在当前阶段内进行线性插值\n",
    "                    ratio = ratio_schedule[i]\n",
    "                    epsilon = max(start_epsilon + ratio * (steps_total / skip_frames - start_step), end_epsilon)\n",
    "            # 跳帧处理\n",
    "            if step_count % skip_frames == 0:\n",
    "                # ε-贪婪策略\n",
    "                if random.random() < epsilon:\n",
    "                    # 根据概率决定采样\n",
    "                    if random.random() < 0.07 * skip_frames:\n",
    "                        action = 1\n",
    "                    else:\n",
    "                        action = 0\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        dist = q_net(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device))\n",
    "                        action = (dist * supports).sum(dim=2).argmax().item()\n",
    "                action_perSkip = action\n",
    "            else:\n",
    "                action = 0\n",
    "\n",
    "            # 执行动作\n",
    "            next_raw_state, reward, done, info = env.step(action)\n",
    "            step_count += 1\n",
    "            steps_total += 1\n",
    "            bSkip = True\n",
    "            if step_count % skip_frames == 0:\n",
    "                bSkip = False\n",
    "                reward_perSkip = 0\n",
    "            if max_step_count < step_count:\n",
    "                max_step_count = step_count\n",
    "            raw_state = next_raw_state\n",
    "            if done:\n",
    "                bSkip = False\n",
    "            # 更新状态队列\n",
    "            processed_frame = preprocess_image(raw_state)\n",
    "            state_queue.append(processed_frame)\n",
    "            next_state = np.array(state_queue)\n",
    "            reward = reward * 0.01  # 缩放奖励\n",
    "            # 得分\n",
    "            bScore = False\n",
    "            if info['score'] > score:\n",
    "                reward += 0.4  # 奖励增加\n",
    "                score = info['score']\n",
    "                bScore = True\n",
    "            if info['score'] > max_score:\n",
    "                max_score = info['score']\n",
    "                if max_score > 100:\n",
    "                    torch.save(q_net.state_dict(), bestScoreFileName) # 保存模型\n",
    "            if done:\n",
    "                reward -= 0.1  # 惩罚\n",
    "            reward_perSkip += reward\n",
    "            if bSkip == False:\n",
    "                replay_buffer.add(state, action_perSkip, reward_perSkip, next_state, done)\n",
    "                state = next_state\n",
    "            total_reward += reward\n",
    "            if total_reward > max_reward_total:\n",
    "                max_reward_total = total_reward\n",
    "            if max_interval_rewards < total_reward:\n",
    "                max_interval_rewards = total_reward\n",
    "\n",
    "            # 经验回放训练\n",
    "            if replay_buffer.size() >= replay_buffer_capacity * 0.1 and bSkip == False:\n",
    "                # 从优先级缓冲区中采样\n",
    "                states, actions, rewards_batch, next_states, dones, weights, n_step_batch, indices = replay_buffer.sample(batch_size, beta, device)\n",
    "\n",
    "                # 计算 Q 网络的分布\n",
    "                dist = q_net(states)\n",
    "                q_dist = dist[range(batch_size), actions]\n",
    "                with torch.no_grad():\n",
    "                    # 目标网络输出分布\n",
    "                    next_dist = target_net(next_states)  # Shape: (batch_size, num_actions, atoms)\n",
    "                    # 行为网络选择动作（Double-DQN）\n",
    "                    next_q_values = (q_net(next_states) * supports).sum(dim=2)  # Shape: (batch_size, num_actions)\n",
    "                    q_value_perInterval += next_q_values.mean().item() / steps_Interval\n",
    "                    next_actions = next_q_values.argmax(dim=1)  # Shape: (batch_size,)\n",
    "                    # 根据行为网络选择的动作提取目标分布\n",
    "                    next_dist = next_dist[range(batch_size), next_actions]  # Shape: (batch_size, atoms)\n",
    "\n",
    "                    # 投影分布\n",
    "                    target_dist = projection_distribution(next_dist, rewards_batch, dones, gamma ** n_step_batch, atoms, v_min, v_max, delta_z, supports)\n",
    "                # KL 散度损失\n",
    "                loss = -(target_dist * q_dist.log()).sum(dim=1) * weights\n",
    "                loss = loss.mean()\n",
    "                loss_perInterval += loss.item() / steps_Interval\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 更新优先级\n",
    "                # Wasserstein 距离计算\n",
    "                td_errors = torch.sum((target_dist - q_dist) * supports, dim=1)  # [batch_size]\n",
    "                priorities = td_errors.abs().detach().cpu().numpy()\n",
    "                replay_buffer.update_priorities(indices, priorities)\n",
    "                update_step_count += 1\n",
    "                steps_perInterval += 1\n",
    "            \n",
    "                # 更新目标网络\n",
    "                if update_step_count >= update_step_interval:\n",
    "                    update_step_count = 0\n",
    "                    target_net.load_state_dict(q_net.state_dict()) # 将q_net的参数复制到target_net中\n",
    "                if steps_perInterval >= steps_Interval:\n",
    "                    # 追加数据到 CSV 文件\n",
    "                    with open(csv_file, 'a') as f:\n",
    "                        current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        f.write(f'{current_time_str},{episode},{steps_total},{epsilon},{loss_perInterval},{q_value_perInterval}\\n')\n",
    "                    steps_perInterval = 0\n",
    "                    loss_perInterval = 0\n",
    "                    q_value_perInterval = 0\n",
    "                # 检查时间间隔\n",
    "                current_time = time.time()\n",
    "                if current_time - last_save_time > 60:\n",
    "                    # 读取配置文件\n",
    "                    config = configparser.ConfigParser()\n",
    "                    if config.read('config.ini'):\n",
    "                        update_step_interval = config.getint('Training', 'update_step_interval')\n",
    "                        lr_temp = config.getfloat('Training', 'lr')\n",
    "                        if lr_temp > 0:\n",
    "                            lr = lr_temp\n",
    "                            state_dict = optimizer.state_dict()\n",
    "                            state_dict['param_groups'][0]['lr'] = lr\n",
    "                            optimizer.load_state_dict(state_dict)\n",
    "                        beta_temp = config.getfloat('Training', 'beta')\n",
    "                        if beta_temp > 0:\n",
    "                            beta = beta_temp\n",
    "                        stop_training = config.getboolean('Training', 'stop_training')\n",
    "                        guideOpen = config.getboolean('Training', 'guideOpen')\n",
    "                        batch_size = config.getint('Training', 'batch_size')\n",
    "                        \n",
    "                    # 设置保存路径和合法文件名\n",
    "                    save_path = \"./models\"\n",
    "                    os.makedirs(save_path, exist_ok=True)  # 确保路径存在\n",
    "                    current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')  # 使用合法字符\n",
    "                    currentNetFile = os.path.join(save_path, f'fb_rgb_v0_{current_time_str}.pth')\n",
    "                    torch.save(q_net.state_dict(), currentNetFile) # 保存模型\n",
    "                    last_save_time = current_time\n",
    "                if current_time - last_print_time >= print_interval:\n",
    "                    last_print_time = current_time\n",
    "                    print(f\"{episode} | {min_interval_rewards:.3f} | {max_interval_rewards:.3f} | {max_reward_total:.3f} | {epsilon:.5f} | {max_score} | {steps_total} | {lr:.8e} | {update_step_interval} | {beta:.5f} | {replay_buffer.size()}\")\n",
    "                    min_interval_rewards = np.inf\n",
    "                    max_interval_rewards = -np.inf\n",
    "                # 更新 beta\n",
    "                beta = min(1.0, beta + beta_increment)\n",
    "\n",
    "        rewards.append(total_reward)  # 确保 append 正常工作\n",
    "        if min_interval_rewards > total_reward:\n",
    "            min_interval_rewards = total_reward\n",
    "        # 重置噪声\n",
    "        q_net.reset_noise()\n",
    "        target_net.reset_noise()\n",
    "        if stop_training:\n",
    "            # 把配置文件的stop_training改为False\n",
    "            config['Training']['stop_training'] = 'False'\n",
    "            with open('config.ini', 'w') as configfile:\n",
    "                config.write(configfile)\n",
    "            break\n",
    "\n",
    "    return q_net, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置文件已创建并写入初始内容。\n",
      "Using device: cuda\n",
      "Episode | min interval reward | max interval reward | max_reward_total | Epsilon | max_score | steps_total | lr | update_step_interval | training_frequency | loss_threshold | beta | replay_buffer.size\n",
      "914 | 31.500 | 152.500 | 152.500 | 0.84152 | 2 | 79211 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 26699\n",
      "1392 | 31.500 | 152.500 | 152.500 | 0.43994 | 2 | 127887 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 43072\n",
      "1838 | 100.500 | 137.500 | 152.500 | 0.06485 | 2 | 173353 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 58374\n",
      "2252 | 100.500 | 195.500 | 195.500 | 0.01000 | 3 | 215836 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 72672\n",
      "2639 | 100.500 | 158.500 | 195.500 | 0.01000 | 3 | 255723 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 86097\n",
      "3009 | 100.500 | 175.500 | 195.500 | 0.01000 | 3 | 294153 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 99025\n",
      "3359 | 100.500 | 158.500 | 195.500 | 0.00815 | 3 | 330854 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "3707 | 100.500 | 175.500 | 195.500 | 0.00596 | 3 | 367374 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4032 | 100.500 | 273.500 | 273.500 | 0.00376 | 5 | 404039 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4347 | 100.500 | 296.500 | 296.500 | 0.00157 | 5 | 440503 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4641 | 100.500 | 273.500 | 296.500 | 0.00100 | 5 | 477045 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "4917 | 100.500 | 296.500 | 296.500 | 0.00100 | 5 | 513666 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "5177 | 100.500 | 327.500 | 327.500 | 0.00100 | 6 | 550354 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "5413 | 100.500 | 367.500 | 367.500 | 0.00100 | 7 | 587099 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5638 | 100.500 | 447.500 | 447.500 | 0.00100 | 9 | 623942 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "5838 | 100.500 | 497.500 | 497.500 | 0.00100 | 11 | 660849 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6024 | 100.500 | 631.500 | 631.500 | 0.00100 | 14 | 697934 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6201 | 100.500 | 610.500 | 631.500 | 0.00100 | 14 | 735067 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6358 | 102.500 | 748.500 | 748.500 | 0.00093 | 17 | 772361 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6482 | 100.500 | 904.500 | 904.500 | 0.00082 | 21 | 809840 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6617 | 100.500 | 752.500 | 904.500 | 0.00071 | 21 | 847334 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6737 | 100.500 | 1282.500 | 1282.500 | 0.00059 | 31 | 885326 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6831 | 100.500 | 1396.500 | 1396.500 | 0.00048 | 34 | 923261 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6892 | 100.500 | 1580.500 | 1580.500 | 0.00039 | 39 | 954456 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6950 | 100.500 | 1428.500 | 1580.500 | 0.00031 | 39 | 981422 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "6993 | 139.500 | 2127.500 | 2127.500 | 0.00023 | 54 | 1007998 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7035 | 100.500 | 2948.500 | 2948.500 | 0.00015 | 75 | 1034872 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7074 | 100.500 | 1793.500 | 2948.500 | 0.00009 | 75 | 1061590 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7101 | 100.500 | 5191.500 | 5191.500 | 0.00007 | 134 | 1088491 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7128 | 100.500 | 2644.500 | 5191.500 | 0.00006 | 134 | 1115267 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7161 | 100.500 | 3328.500 | 5191.500 | 0.00004 | 134 | 1142625 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7194 | 108.500 | 2629.000 | 5191.500 | 0.00002 | 134 | 1170234 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7224 | 152.500 | 4089.500 | 5191.500 | 0.00000 | 134 | 1197643 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7243 | 139.500 | 6080.500 | 6080.500 | 0.00000 | 158 | 1225302 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7269 | 100.500 | 3519.500 | 6080.500 | 0.00000 | 158 | 1252811 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7294 | 100.500 | 2987.500 | 6080.500 | 0.00000 | 158 | 1281238 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7326 | 102.500 | 3632.500 | 6080.500 | 0.00000 | 158 | 1313113 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7357 | 189.500 | 5380.500 | 6080.500 | 0.00000 | 158 | 1344995 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7382 | 105.500 | 4579.000 | 6080.500 | 0.00000 | 158 | 1376529 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7404 | 112.500 | 5778.500 | 6080.500 | 0.00000 | 158 | 1405532 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7424 | 100.500 | 6754.500 | 6754.500 | 0.00000 | 175 | 1433167 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7451 | 139.500 | 4006.000 | 6754.500 | 0.00000 | 175 | 1461010 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7474 | 108.500 | 5356.500 | 6754.500 | 0.00000 | 175 | 1488937 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7491 | 152.500 | 6006.500 | 6754.500 | 0.00000 | 175 | 1516940 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7511 | 145.500 | 3869.500 | 6754.500 | 0.00000 | 175 | 1544925 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7535 | 251.500 | 3675.500 | 6754.500 | 0.00000 | 175 | 1572875 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7557 | 220.500 | 3632.500 | 6754.500 | 0.00000 | 175 | 1600906 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7575 | 105.500 | 3411.500 | 6754.500 | 0.00000 | 175 | 1628938 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7590 | 175.500 | 5251.000 | 6754.500 | 0.00000 | 175 | 1656985 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7611 | 176.500 | 7417.500 | 7417.500 | 0.00000 | 193 | 1684990 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7632 | 100.500 | 6505.500 | 7417.500 | 0.00000 | 193 | 1713177 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7654 | 100.500 | 4662.500 | 7417.500 | 0.00000 | 193 | 1741367 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7670 | 196.500 | 5380.500 | 7417.500 | 0.00000 | 193 | 1769587 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7685 | 288.500 | 7022.500 | 7417.500 | 0.00000 | 193 | 1797741 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7704 | 213.500 | 5648.500 | 7417.500 | 0.00000 | 193 | 1825976 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7719 | 403.500 | 5250.500 | 7417.500 | 0.00000 | 193 | 1854192 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7730 | 251.500 | 8917.500 | 8917.500 | 0.00000 | 232 | 1882399 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7740 | 288.500 | 7341.500 | 8917.500 | 0.00000 | 232 | 1910669 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7756 | 228.500 | 4240.500 | 8917.500 | 0.00000 | 232 | 1938952 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7772 | 179.500 | 6863.500 | 8917.500 | 0.00000 | 232 | 1967280 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7787 | 192.500 | 6717.500 | 8917.500 | 0.00000 | 232 | 1995636 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7807 | 116.500 | 5768.500 | 8917.500 | 0.00000 | 232 | 2024176 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7819 | 377.500 | 6501.500 | 8917.500 | 0.00000 | 232 | 2052585 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7832 | 364.500 | 6694.500 | 8917.500 | 0.00000 | 232 | 2080967 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7849 | 150.500 | 4414.500 | 8917.500 | 0.00000 | 232 | 2109259 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7863 | 335.500 | 5007.500 | 8917.500 | 0.00000 | 232 | 2137642 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7875 | 299.500 | 11293.500 | 11293.500 | 0.00000 | 295 | 2165807 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7890 | 212.500 | 8467.500 | 11293.500 | 0.00000 | 295 | 2194160 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7906 | 175.500 | 4821.500 | 11293.500 | 0.00000 | 295 | 2222533 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7923 | 105.500 | 6337.500 | 11293.500 | 0.00000 | 295 | 2250910 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7940 | 100.500 | 4213.500 | 11293.500 | 0.00000 | 295 | 2279228 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7958 | 340.500 | 5988.500 | 11293.500 | 0.00000 | 295 | 2307608 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7972 | 100.500 | 5354.500 | 11293.500 | 0.00000 | 295 | 2336005 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7982 | 440.500 | 7851.500 | 11293.500 | 0.00000 | 295 | 2364472 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7999 | 144.500 | 6338.500 | 11293.500 | 0.00000 | 295 | 2392910 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8008 | 100.500 | 6824.500 | 11293.500 | 0.00000 | 295 | 2421344 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8020 | 139.500 | 8131.500 | 11293.500 | 0.00000 | 295 | 2449753 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8037 | 100.500 | 9684.500 | 11293.500 | 0.00000 | 295 | 2478226 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8051 | 212.500 | 9225.500 | 11293.500 | 0.00000 | 295 | 2506692 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8067 | 226.500 | 5517.500 | 11293.500 | 0.00000 | 295 | 2535192 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8077 | 367.500 | 6776.000 | 11293.500 | 0.00000 | 295 | 2563696 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8088 | 564.500 | 9789.500 | 11293.500 | 0.00000 | 295 | 2592251 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8101 | 212.500 | 8249.500 | 11293.500 | 0.00000 | 295 | 2620775 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8115 | 102.500 | 8169.500 | 11293.500 | 0.00000 | 295 | 2649313 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8132 | 176.500 | 3371.500 | 11293.500 | 0.00000 | 295 | 2677822 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8142 | 288.500 | 6338.500 | 11293.500 | 0.00000 | 295 | 2706355 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8159 | 154.500 | 4735.500 | 11293.500 | 0.00000 | 295 | 2734849 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8168 | 640.500 | 12068.500 | 12068.500 | 0.00000 | 315 | 2763329 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8181 | 100.500 | 6471.000 | 12068.500 | 0.00000 | 315 | 2791799 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8187 | 290.500 | 9758.500 | 12068.500 | 0.00000 | 315 | 2820319 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8195 | 576.500 | 10609.500 | 12068.500 | 0.00000 | 315 | 2848803 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8210 | 175.500 | 6825.500 | 12068.500 | 0.00000 | 315 | 2877300 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8226 | 121.500 | 4248.500 | 12068.500 | 0.00000 | 315 | 2905882 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8241 | 327.500 | 4696.500 | 12068.500 | 0.00000 | 315 | 2934429 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8250 | 1061.500 | 12259.500 | 12259.500 | 0.00000 | 320 | 2962997 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8266 | 218.500 | 4898.500 | 12259.500 | 0.00000 | 320 | 2991634 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8281 | 137.500 | 7454.500 | 12259.500 | 0.00000 | 320 | 3020229 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8297 | 367.500 | 7665.500 | 12259.500 | 0.00000 | 320 | 3048855 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8308 | 102.500 | 6446.500 | 12259.500 | 0.00000 | 320 | 3077500 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8319 | 100.500 | 9524.500 | 12259.500 | 0.00000 | 320 | 3106132 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8335 | 112.500 | 10759.500 | 12259.500 | 0.00000 | 320 | 3134751 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8345 | 259.500 | 7632.000 | 12259.500 | 0.00000 | 320 | 3163378 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8358 | 112.500 | 8129.500 | 12259.500 | 0.00000 | 320 | 3192052 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8368 | 487.500 | 12303.000 | 12303.000 | 0.00000 | 321 | 3220767 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8381 | 143.500 | 13786.500 | 13786.500 | 0.00000 | 360 | 3249365 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8393 | 105.500 | 8155.500 | 13786.500 | 0.00000 | 360 | 3278039 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8412 | 116.500 | 4554.500 | 13786.500 | 0.00000 | 360 | 3306725 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8424 | 416.500 | 5152.500 | 13786.500 | 0.00000 | 360 | 3335396 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8440 | 106.500 | 7666.500 | 13786.500 | 0.00000 | 360 | 3364112 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8448 | 349.500 | 7398.500 | 13786.500 | 0.00000 | 360 | 3392874 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8458 | 728.500 | 6483.500 | 13786.500 | 0.00000 | 360 | 3421582 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8468 | 229.500 | 12109.500 | 13786.500 | 0.00000 | 360 | 3450410 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8483 | 110.500 | 5419.500 | 13786.500 | 0.00000 | 360 | 3479125 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8491 | 212.500 | 14845.500 | 14845.500 | 0.00000 | 388 | 3507847 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8504 | 152.500 | 6154.500 | 14845.500 | 0.00000 | 388 | 3536461 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8515 | 901.500 | 7968.500 | 14845.500 | 0.00000 | 388 | 3565252 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8521 | 349.500 | 17942.500 | 17942.500 | 0.00000 | 470 | 3593949 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8530 | 1070.500 | 6444.500 | 17942.500 | 0.00000 | 470 | 3622793 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8540 | 262.500 | 16895.500 | 17942.500 | 0.00000 | 470 | 3651614 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8547 | 373.500 | 7546.000 | 17942.500 | 0.00000 | 470 | 3680415 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8558 | 108.500 | 10603.500 | 17942.500 | 0.00000 | 470 | 3709204 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8571 | 186.500 | 7531.000 | 17942.500 | 0.00000 | 470 | 3737969 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8582 | 120.500 | 11540.500 | 17942.500 | 0.00000 | 470 | 3766703 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8594 | 364.500 | 6538.500 | 17942.500 | 0.00000 | 470 | 3795566 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8602 | 802.500 | 5419.500 | 17942.500 | 0.00000 | 470 | 3824426 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8610 | 330.500 | 13095.500 | 17942.500 | 0.00000 | 470 | 3853300 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8620 | 651.500 | 7417.500 | 17942.500 | 0.00000 | 470 | 3882073 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8629 | 1282.500 | 8169.500 | 17942.500 | 0.00000 | 470 | 3910901 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8641 | 149.500 | 7059.500 | 17942.500 | 0.00000 | 470 | 3939749 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8652 | 592.500 | 12189.500 | 17942.500 | 0.00000 | 470 | 3968510 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8660 | 759.500 | 7820.500 | 17942.500 | 0.00000 | 470 | 3997231 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8673 | 527.500 | 7358.500 | 17942.500 | 0.00000 | 470 | 4026087 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8688 | 222.500 | 4548.500 | 17942.500 | 0.00000 | 470 | 4054837 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8700 | 259.500 | 6141.000 | 17942.500 | 0.00000 | 470 | 4086953 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8706 | 251.500 | 17215.500 | 17942.500 | 0.00000 | 470 | 4120070 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8719 | 100.500 | 6157.000 | 17942.500 | 0.00000 | 470 | 4153334 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8730 | 345.500 | 8572.500 | 17942.500 | 0.00000 | 470 | 4186583 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8742 | 100.500 | 4696.500 | 17942.500 | 0.00000 | 470 | 4220000 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8762 | 100.500 | 7749.500 | 17942.500 | 0.00000 | 470 | 4253501 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8779 | 115.500 | 5882.500 | 17942.500 | 0.00000 | 470 | 4287116 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8792 | 100.500 | 7888.500 | 17942.500 | 0.00000 | 470 | 4320589 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8808 | 114.500 | 8702.500 | 17942.500 | 0.00000 | 470 | 4351744 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8817 | 216.500 | 12791.500 | 17942.500 | 0.00000 | 470 | 4384961 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8827 | 229.500 | 8996.500 | 17942.500 | 0.00000 | 470 | 4414093 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8833 | 251.500 | 12752.500 | 17942.500 | 0.00000 | 470 | 4442415 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8845 | 273.500 | 8036.000 | 17942.500 | 0.00000 | 470 | 4471486 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8858 | 149.500 | 8276.500 | 17942.500 | 0.00000 | 470 | 4500682 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8869 | 137.500 | 8090.500 | 17942.500 | 0.00000 | 470 | 4529938 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8885 | 102.500 | 6840.500 | 17942.500 | 0.00000 | 470 | 4559169 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8901 | 137.500 | 5808.500 | 17942.500 | 0.00000 | 470 | 4587163 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8909 | 234.500 | 7367.500 | 17942.500 | 0.00000 | 470 | 4616540 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8914 | 327.500 | 12952.500 | 17942.500 | 0.00000 | 470 | 4645312 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8921 | 839.500 | 10587.500 | 17942.500 | 0.00000 | 470 | 4673462 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8930 | 100.500 | 10859.500 | 17942.500 | 0.00000 | 470 | 4701694 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8942 | 677.500 | 7797.500 | 17942.500 | 0.00000 | 470 | 4730056 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8951 | 310.500 | 12470.500 | 17942.500 | 0.00000 | 470 | 4759383 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8962 | 262.500 | 5309.500 | 17942.500 | 0.00000 | 470 | 4788659 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8970 | 500.500 | 9393.500 | 17942.500 | 0.00000 | 470 | 4818052 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8979 | 184.500 | 12220.500 | 17942.500 | 0.00000 | 470 | 4846712 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8984 | 349.500 | 14731.500 | 17942.500 | 0.00000 | 470 | 4875395 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8993 | 561.500 | 7743.500 | 17942.500 | 0.00000 | 470 | 4904129 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9004 | 645.500 | 8877.500 | 17942.500 | 0.00000 | 470 | 4933125 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9012 | 571.500 | 9104.500 | 17942.500 | 0.00000 | 470 | 4961889 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9020 | 598.500 | 7509.500 | 17942.500 | 0.00000 | 470 | 4990234 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9035 | 105.500 | 7128.500 | 17942.500 | 0.00000 | 470 | 5018609 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9048 | 216.500 | 8803.500 | 17942.500 | 0.00000 | 470 | 5047017 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9063 | 364.500 | 6748.500 | 17942.500 | 0.00000 | 470 | 5075399 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9072 | 181.500 | 6981.500 | 17942.500 | 0.00000 | 470 | 5103835 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9078 | 288.500 | 11450.000 | 17942.500 | 0.00000 | 470 | 5132288 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9087 | 327.500 | 12470.500 | 17942.500 | 0.00000 | 470 | 5160779 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9101 | 212.500 | 6672.500 | 17942.500 | 0.00000 | 470 | 5189696 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9112 | 212.500 | 9460.500 | 17942.500 | 0.00000 | 470 | 5217992 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9124 | 121.500 | 7340.500 | 17942.500 | 0.00000 | 470 | 5246238 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9132 | 217.500 | 7589.500 | 17942.500 | 0.00000 | 470 | 5274576 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9139 | 638.500 | 11274.500 | 17942.500 | 0.00000 | 470 | 5303817 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9147 | 718.500 | 12600.500 | 17942.500 | 0.00000 | 470 | 5332297 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9159 | 364.500 | 10988.500 | 17942.500 | 0.00000 | 470 | 5360960 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9168 | 423.500 | 8621.000 | 17942.500 | 0.00000 | 470 | 5389435 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9178 | 416.500 | 9408.500 | 17942.500 | 0.00000 | 470 | 5418131 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9184 | 1656.500 | 8930.500 | 17942.500 | 0.00000 | 470 | 5447787 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9195 | 259.500 | 7970.500 | 17942.500 | 0.00000 | 470 | 5477451 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9204 | 271.500 | 8062.500 | 17942.500 | 0.00000 | 470 | 5507207 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9211 | 558.500 | 11998.500 | 17942.500 | 0.00000 | 470 | 5536271 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9218 | 709.500 | 13637.500 | 17942.500 | 0.00000 | 470 | 5565928 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9233 | 100.500 | 5913.500 | 17942.500 | 0.00000 | 470 | 5595169 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9242 | 327.500 | 6650.500 | 17942.500 | 0.00000 | 470 | 5624795 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9246 | 791.500 | 16864.500 | 17942.500 | 0.00000 | 470 | 5653446 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9258 | 327.500 | 12008.500 | 17942.500 | 0.00000 | 470 | 5681211 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9268 | 403.500 | 7968.500 | 17942.500 | 0.00000 | 470 | 5709190 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9275 | 272.500 | 16382.500 | 17942.500 | 0.00000 | 470 | 5737148 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9282 | 516.500 | 9006.500 | 17942.500 | 0.00000 | 470 | 5765853 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9291 | 100.500 | 12041.500 | 17942.500 | 0.00000 | 470 | 5795137 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9300 | 152.500 | 8952.500 | 17942.500 | 0.00000 | 470 | 5824562 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9307 | 221.500 | 9654.500 | 17942.500 | 0.00000 | 470 | 5853908 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9325 | 149.500 | 4262.500 | 17942.500 | 0.00000 | 470 | 5883574 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9333 | 259.500 | 10094.500 | 17942.500 | 0.00000 | 470 | 5913260 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9341 | 900.500 | 10563.500 | 17942.500 | 0.00000 | 470 | 5942895 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9349 | 120.500 | 11992.500 | 17942.500 | 0.00000 | 470 | 5972044 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9355 | 481.500 | 9104.500 | 17942.500 | 0.00000 | 470 | 6000463 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9362 | 707.500 | 8467.500 | 17942.500 | 0.00000 | 470 | 6030232 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9373 | 271.500 | 10368.500 | 17942.500 | 0.00000 | 470 | 6058743 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9385 | 259.500 | 6429.500 | 17942.500 | 0.00000 | 470 | 6085913 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9399 | 217.500 | 5988.500 | 17942.500 | 0.00000 | 470 | 6114727 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9405 | 867.500 | 14508.500 | 17942.500 | 0.00000 | 470 | 6144189 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9414 | 1316.500 | 10001.500 | 17942.500 | 0.00000 | 470 | 6173441 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9424 | 197.500 | 9355.000 | 17942.500 | 0.00000 | 470 | 6202858 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9432 | 112.500 | 12082.500 | 17942.500 | 0.00000 | 470 | 6231076 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9442 | 138.500 | 7395.500 | 17942.500 | 0.00000 | 470 | 6259906 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9451 | 1057.500 | 7750.500 | 17942.500 | 0.00000 | 470 | 6288863 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9461 | 142.500 | 5854.500 | 17942.500 | 0.00000 | 470 | 6316866 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9468 | 334.500 | 11302.000 | 17942.500 | 0.00000 | 470 | 6345849 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9477 | 373.500 | 11780.500 | 17942.500 | 0.00000 | 470 | 6374359 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9484 | 2247.500 | 9752.500 | 17942.500 | 0.00000 | 470 | 6402484 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9493 | 69.500 | 10609.500 | 17942.500 | 0.00000 | 470 | 6432136 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9502 | 158.500 | 10761.500 | 17942.500 | 0.00000 | 470 | 6460401 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9510 | 527.500 | 7356.500 | 17942.500 | 0.00000 | 470 | 6489156 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9516 | 1356.500 | 12600.500 | 17942.500 | 0.00000 | 470 | 6518530 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9526 | 117.500 | 6581.500 | 17942.500 | 0.00000 | 470 | 6547045 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9538 | 385.500 | 8575.000 | 17942.500 | 0.00000 | 470 | 6576184 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9546 | 1322.500 | 11120.500 | 17942.500 | 0.00000 | 470 | 6605373 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9550 | 4477.500 | 12129.500 | 17942.500 | 0.00000 | 470 | 6633698 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9563 | 149.500 | 7743.500 | 17942.500 | 0.00000 | 470 | 6662845 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9568 | 330.500 | 10396.500 | 17942.500 | 0.00000 | 470 | 6691844 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9578 | 137.500 | 17959.500 | 17959.500 | 0.00000 | 470 | 6720261 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9585 | 425.500 | 12445.000 | 17959.500 | 0.00000 | 470 | 6749615 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9594 | 100.500 | 13825.500 | 17959.500 | 0.00000 | 470 | 6778196 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9606 | 668.500 | 4794.500 | 17959.500 | 0.00000 | 470 | 6806674 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9615 | 479.500 | 8196.500 | 17959.500 | 0.00000 | 470 | 6836363 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9623 | 497.500 | 6110.500 | 17959.500 | 0.00000 | 470 | 6864946 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9627 | 972.500 | 16820.500 | 17959.500 | 0.00000 | 470 | 6893541 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9634 | 675.500 | 9940.500 | 17959.500 | 0.00000 | 470 | 6923301 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9642 | 518.500 | 10559.500 | 17959.500 | 0.00000 | 470 | 6952125 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9648 | 364.500 | 11810.000 | 17959.500 | 0.00000 | 470 | 6981576 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9658 | 373.500 | 12913.500 | 17959.500 | 0.00000 | 470 | 7011335 | 1.00000000e-07 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9665 | 614.500 | 8865.000 | 17959.500 | 0.00000 | 470 | 7039976 | 1.00000000e-07 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9712 | 31.500 | 11048.500 | 17959.500 | 0.00000 | 470 | 7066088 | 1.00000000e-04 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9809 | 100.500 | 1103.500 | 17959.500 | 0.00000 | 470 | 7093940 | 1.00000000e-04 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9899 | 100.500 | 1337.500 | 17959.500 | 0.00000 | 470 | 7121193 | 1.00000000e-04 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "10014 | 100.500 | 783.500 | 17959.500 | 0.00000 | 470 | 7149871 | 1.00000000e-04 | 100 | 0 | 0.500 | 1.00000 | 100000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import flappy_bird_gym\n",
    "import configparser\n",
    "\n",
    "# 创建ConfigParser对象\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# 添加配置项\n",
    "config['Training'] = {\n",
    "    'update_step_interval': '100',\n",
    "    'lr': '0.000001',\n",
    "    'delta_training_frequency': '0',\n",
    "    'beta': '-0.1',\n",
    "    'stop_training': 'False',\n",
    "    'batch_size': '256'\n",
    "}\n",
    "\n",
    "# 写入配置文件\n",
    "with open('config.ini', 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "\n",
    "print(\"配置文件已创建并写入初始内容。\")\n",
    "\n",
    "# 确保环境是 FlappyBird-v0\n",
    "env = gym.make(\"FlappyBird-rgb-v0\")\n",
    "import os\n",
    "import pygame\n",
    "\n",
    "# 将声音输出重定向到\"无声设备\"\n",
    "os.environ[\"SDL_AUDIODRIVER\"] = \"dummy\"  # 设置虚拟音频驱动\n",
    "pygame.mixer.quit()  # 重新初始化以应用设置\n",
    "\n",
    "# 训练网络\n",
    "q_net, rewards = train_dueling_dqn_noise_MultiStep_PER(\n",
    "    env,\n",
    "    num_episodes=50000,\n",
    "    batch_size=256,\n",
    "    gamma=0.99,\n",
    "    epsilon_schedule=[(0, 1), (20000, 1), (60000, 0.01), (100000, 0.01), (150000, 0.001), (250000, 0.001), (350000, 0.0001), (400000, 0.0)],\n",
    "    lr=1e-6,\n",
    "    alpha=0.6,\n",
    "    beta_start=0.4,\n",
    "    beta_increment=1e-4,\n",
    "    number_of_states=4,\n",
    "    skip_frames=3,\n",
    "    modelFile = None\n",
    ")\n",
    "'''q_net, rewards = train_rainbow_dqn(\n",
    "    env,\n",
    "    num_episodes=50000,\n",
    "    batch_size=256,\n",
    "    gamma=0.99,\n",
    "    epsilon_schedule=[(0, 1), (50000, 1), (60000, 0.01), (100000, 0.01), (150000, 0.001), (250000, 0.001), (350000, 0.0001), (400000, 0.0)],\n",
    "    lr=1e-6,\n",
    "    alpha=0.6,\n",
    "    beta_start=0.4,\n",
    "    beta_increment=1e-4,\n",
    "    number_of_states=4,\n",
    "    skip_frames=1,\n",
    "    atoms=101,\n",
    "    v_min=-0.1,\n",
    "    v_max=4.59,\n",
    "    modelFile = None\n",
    ")'''\n",
    "plot_dataList(rewards)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
