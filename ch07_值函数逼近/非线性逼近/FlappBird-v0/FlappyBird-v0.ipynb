{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "# Q网络定义\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 经验回放池\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        states, actions, rewards, next_states, dones = zip(*random.sample(self.buffer, batch_size))\n",
    "        return (\n",
    "            torch.tensor(np.stack(states), dtype=torch.float32),\n",
    "            torch.tensor(actions, dtype=torch.int64),\n",
    "            torch.tensor(rewards, dtype=torch.float32),\n",
    "            torch.tensor(np.stack(next_states), dtype=torch.float32),\n",
    "            torch.tensor(dones, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_dataList(rewards, xStart=0):\n",
    "    # 设置图像的宽度为 12 英寸\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.plot(range(xStart, len(rewards) + xStart), rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Total Reward vs Episode')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.V = nn.Linear(128, 1)\n",
    "        self.A = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        V = self.V(x)\n",
    "        A = self.A(x)\n",
    "        Q = V + (A - A.mean(dim=1, keepdim=True))\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6):\n",
    "        \"\"\"\n",
    "        capacity: 缓冲区容量\n",
    "        alpha: 优先级比例，0表示完全随机采样，1表示完全按优先级采样\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.priorities = np.zeros((capacity,), dtype=np.float32)\n",
    "        self.position = 0\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"添加新经验，优先级初始化为最大值以确保被采样\"\"\"\n",
    "        max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append((state, action, reward, next_state, done))\n",
    "        else:\n",
    "            self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.priorities[self.position] = max_priority\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        \"\"\"\n",
    "        采样带优先级的批次数据\n",
    "        beta: 重要性采样的偏置修正参数\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == self.capacity:\n",
    "            priorities = self.priorities\n",
    "        else:\n",
    "            priorities = self.priorities[:self.position]\n",
    "        \n",
    "        # 根据优先级分布计算采样概率\n",
    "        probs = priorities ** self.alpha\n",
    "        probs /= probs.sum()\n",
    "\n",
    "        # 按照概率采样\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[idx] for idx in indices]\n",
    "\n",
    "        # 计算重要性采样权重\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()\n",
    "\n",
    "        # 解包样本\n",
    "        states, actions, rewards, next_states, dones = zip(*samples)\n",
    "        return (\n",
    "            torch.tensor(np.stack(states), dtype=torch.float32),\n",
    "            torch.tensor(actions, dtype=torch.int64),\n",
    "            torch.tensor(rewards, dtype=torch.float32),\n",
    "            torch.tensor(np.stack(next_states), dtype=torch.float32),\n",
    "            torch.tensor(dones, dtype=torch.float32),\n",
    "            torch.tensor(weights, dtype=torch.float32),\n",
    "            indices,\n",
    "        )\n",
    "\n",
    "    def update_priorities(self, indices, priorities):\n",
    "        \"\"\"根据新的 TD Error 更新优先级\"\"\"\n",
    "        self.priorities[indices] = priorities\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, std_init=0.5):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        # 可训练参数\n",
    "        self.weight_mu = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.bias_mu = nn.Parameter(torch.empty(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.empty(out_features))\n",
    "\n",
    "        # 非参数化噪声\n",
    "        self.register_buffer(\"weight_epsilon\", torch.empty(out_features, in_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.empty(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # 初始化可训练参数\n",
    "        bound = 1 / self.in_features ** 0.5\n",
    "        self.weight_mu.data.uniform_(-bound, bound)\n",
    "        self.weight_sigma.data.fill_(self.std_init / (self.in_features ** 0.5))\n",
    "        self.bias_mu.data.uniform_(-bound, bound)\n",
    "        self.bias_sigma.data.fill_(self.std_init / (self.in_features ** 0.5))\n",
    "\n",
    "    def reset_noise(self):\n",
    "        # 采样噪声\n",
    "        self.weight_epsilon.normal_()\n",
    "        self.bias_epsilon.normal_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            weight = self.weight_mu + self.weight_sigma * self.weight_epsilon\n",
    "            bias = self.bias_mu + self.bias_sigma * self.bias_epsilon\n",
    "        else:\n",
    "            weight = self.weight_mu\n",
    "            bias = self.bias_mu\n",
    "        return torch.nn.functional.linear(x, weight, bias)\n",
    "\n",
    "class Dueling_NoisyDQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Dueling_NoisyDQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            NoisyLinear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            NoisyLinear(128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.V = NoisyLinear(128, 1)\n",
    "        self.A = NoisyLinear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        V = self.V(x)\n",
    "        A = self.A(x)\n",
    "        Q = V + (A - A.mean(dim=1, keepdim=True))\n",
    "        return Q\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, NoisyLinear):\n",
    "                m.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepPrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6, n_step=3, gamma=0.99):\n",
    "        \"\"\"\n",
    "        capacity: 缓冲区容量\n",
    "        alpha: 优先级比例，0表示完全随机采样，1表示完全按优先级采样\n",
    "        n_step: 多步时间跨度\n",
    "        gamma: 折扣因子\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.priorities = np.zeros((capacity,), dtype=np.float32)\n",
    "        self.position = 0\n",
    "        self.alpha = alpha\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # 用于多步存储的临时队列\n",
    "        self.n_step_queue = []\n",
    "\n",
    "    def _get_n_step_info(self):\n",
    "        \"\"\"从 n_step_queue 计算 n 步累计奖励和目标状态\"\"\"\n",
    "        R = 0\n",
    "        for idx, (_, _, reward, _, _) in enumerate(self.n_step_queue):\n",
    "            R += (self.gamma ** idx) * reward\n",
    "        state, action, _, next_state, done = self.n_step_queue[0]\n",
    "        final_next_state, final_done = self.n_step_queue[-1][3], self.n_step_queue[-1][4]\n",
    "        return (state, action, R, final_next_state, final_done)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        添加新经验。\n",
    "        使用 n_step_queue 缓存多步数据，只有在积累到 n 步时才存入 buffer。\n",
    "        在轨迹结束时处理剩余的队列。\n",
    "        \"\"\"\n",
    "        self.n_step_queue.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        # 如果 n_step_queue 满了，处理一个完整的 n-step 转移\n",
    "        if len(self.n_step_queue) == self.n_step:\n",
    "            n_step_transition = self._get_n_step_info()\n",
    "            max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "            if len(self.buffer) < self.capacity:\n",
    "                self.buffer.append(n_step_transition)\n",
    "            else:\n",
    "                self.buffer[self.position] = n_step_transition\n",
    "            self.priorities[self.position] = max_priority\n",
    "            self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "            # 移除队列的第一个元素\n",
    "            self.n_step_queue.pop(0)\n",
    "\n",
    "        # 如果 done=True，处理剩余队列中的短步转移\n",
    "        if done:\n",
    "            while self.n_step_queue:\n",
    "                n_step_transition = self._get_n_step_info()\n",
    "                max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "                if len(self.buffer) < self.capacity:\n",
    "                    self.buffer.append(n_step_transition)\n",
    "                else:\n",
    "                    self.buffer[self.position] = n_step_transition\n",
    "                self.priorities[self.position] = max_priority\n",
    "                self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "                # 移除队列的第一个元素\n",
    "                self.n_step_queue.pop(0)\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4, device='cpu'):\n",
    "        \"\"\"\n",
    "        采样带优先级的批次数据。\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == self.capacity:\n",
    "            priorities = self.priorities\n",
    "        else:\n",
    "            priorities = self.priorities[:self.position]\n",
    "\n",
    "        # 根据优先级分布计算采样概率\n",
    "        probs = priorities ** self.alpha\n",
    "        probs /= probs.sum()\n",
    "\n",
    "        # 按照概率采样\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[idx] for idx in indices]\n",
    "\n",
    "        # 计算重要性采样权重\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()\n",
    "\n",
    "        # 解包样本\n",
    "        states, actions, rewards, next_states, dones = zip(*samples)\n",
    "        return (\n",
    "            torch.tensor(np.stack(states), dtype=torch.float32).to(device),\n",
    "            torch.tensor(actions, dtype=torch.int64).to(device),\n",
    "            torch.tensor(rewards, dtype=torch.float32).to(device),\n",
    "            torch.tensor(np.stack(next_states), dtype=torch.float32).to(device),\n",
    "            torch.tensor(dones, dtype=torch.float32).to(device),\n",
    "            torch.tensor(weights, dtype=torch.float32).to(device),\n",
    "            indices,\n",
    "        )\n",
    "\n",
    "    def update_priorities(self, indices, priorities):\n",
    "        \"\"\"根据新的 TD Error 更新优先级\"\"\"\n",
    "        self.priorities[indices] = priorities\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def current_queue_size(self):\n",
    "        return len(self.n_step_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.3 (SDL 2.0.16, Python 3.8.20)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pygame\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import configparser\n",
    "\n",
    "fileName = 'models/fb_v0_no_score_2024-12-10_21-45-31.pth'\n",
    "bestScoreFileName = 'flappy_bird_v0_model_best_score.pth'\n",
    "stopTrainingFileName = 'flappy_bird_stop.txt'\n",
    "guideFileName = 'result1/models/fb_v0_no_score_2024-12-07_16-37-46.pth'\n",
    "\n",
    "def train_dueling_dqn_noise_MultiStep_PER(env, num_episodes=500, batch_size=64, gamma=0.99, \n",
    "                                          epsilon_schedule=[(0, 1.0), (20000, 0.1), (700000, 0.01), (1040000, 0.001), (1720000, 0.0001), (2060000, 0.0)], \n",
    "                                          lr=1e-3, alpha=0.6, beta_start=0.4, beta_increment=1e-4):\n",
    "    # 新的状态维度为原始状态维度的 8 倍\n",
    "    number_of_states = 12\n",
    "    input_dim = env.observation_space.shape[0] * number_of_states\n",
    "    output_dim = env.action_space.n\n",
    "\n",
    "    # 检查是否有GPU可用\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    q_net = Dueling_NoisyDQN(input_dim, output_dim).to(device)\n",
    "    # 判断是否存在fileName文件\n",
    "    if os.path.exists(fileName):\n",
    "        q_net.load_state_dict(torch.load(fileName, weights_only=True, map_location=device))\n",
    "        print(\"模型已加载\")\n",
    "    q_net.train() # 设置为训练模式，需要通过训练更新参数，该行代码可以省略，因为默认就是训练模式\n",
    "    target_net = Dueling_NoisyDQN(input_dim, output_dim).to(device)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "    target_net.eval() # 设置为评估模式，不需要通过训练更新参数，更新时只需要复制q_net的参数\n",
    "    guider_net = Dueling_NoisyDQN(env.observation_space.shape[0], output_dim)\n",
    "    guideOpen = False\n",
    "    if os.path.exists(guideFileName):\n",
    "        guider_net.load_state_dict(torch.load(guideFileName, weights_only=True))\n",
    "        guider_net = guider_net.to(device)\n",
    "        guider_net.eval()\n",
    "        print(\"引导模型已加载\")\n",
    "    else:\n",
    "        guider_net = None\n",
    "\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=lr)\n",
    "    replay_buffer_capacity = 100000\n",
    "    replay_buffer = MultiStepPrioritizedReplayBuffer(capacity=replay_buffer_capacity, alpha=alpha, n_step=20, gamma=gamma)\n",
    "    epsilon = epsilon_schedule[0][1]\n",
    "    beta = beta_start\n",
    "    rewards = []  # 确保它是一个列表\n",
    "    max_reward_total = -np.inf\n",
    "    max_interval_rewards = -np.inf\n",
    "    min_interval_rewards = np.inf\n",
    "    max_score = 0\n",
    "    max_step_count = 0\n",
    "    update_step_count = 0\n",
    "    update_step_interval = 200\n",
    "    print_interval = 300  # 间隔（单位：秒）\n",
    "    # 记录训练开始的时间\n",
    "    last_save_time = time.time()\n",
    "    last_print_time = last_save_time\n",
    "    stop_training = False\n",
    "    steps_Interval = 1000\n",
    "    steps_perInterval = 0\n",
    "    steps_total = 0\n",
    "    loss_perInterval = 0\n",
    "    q_value_perInterval = 0\n",
    "    delta_training_frequency = 3\n",
    "    delta_loss_threshold = 0.1\n",
    "    # 获取当前时间戳\n",
    "    current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    csv_file = f'dueling_dqn_noise_MultiStep_PER_{current_time_str}.csv'\n",
    "    aim_score = 5000\n",
    "\n",
    "    # 创建表格文件，列名分别为：总步数、epsilon、平均损失、平均Q值\n",
    "    with open(csv_file, 'w') as f:\n",
    "        f.write('Time,episode,Steps,epsilon,loss,Q_value\\n')\n",
    "        f.close()\n",
    "    ratio_schedule = []\n",
    "    for i in range(len(epsilon_schedule) - 1):\n",
    "        start_step, start_epsilon = epsilon_schedule[i]\n",
    "        end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "        ratio = (end_epsilon - start_epsilon) / (end_step - start_step)\n",
    "        ratio_schedule.append(ratio)\n",
    "    \n",
    "    print(f\"Episode | min interval reward | max interval reward | max_reward_total | Epsilon | max_score | steps_total | lr | update_step_interval | training_frequency | loss_threshold | beta | replay_buffer.size\")\n",
    "    for episode in range(num_episodes):\n",
    "        raw_state = env.reset()  # 返回 numpy.ndarray\n",
    "        state_queue = deque([raw_state.copy() for _ in range(number_of_states)], maxlen=number_of_states)  # 初始化队列，初始状态填充队列\n",
    "        state = np.concatenate(state_queue) # 将队列内容展平\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        step_count = 0\n",
    "        score = 0\n",
    "\n",
    "        while not done:  # 每个 episode 的最大步数\n",
    "            # 根据多段线性衰减策略计算 epsilon\n",
    "            for i in range(len(epsilon_schedule) - 1):\n",
    "                start_step, start_epsilon = epsilon_schedule[i]\n",
    "                end_step, end_epsilon = epsilon_schedule[i + 1]\n",
    "                if start_step <= steps_total < end_step:\n",
    "                    # 在当前阶段内进行线性插值\n",
    "                    ratio = ratio_schedule[i]\n",
    "                    epsilon = max(start_epsilon + ratio * (steps_total - start_step), end_epsilon)\n",
    "            # ε-贪婪策略\n",
    "            if random.random() < epsilon:\n",
    "                # 根据概率决定采样\n",
    "                if random.random() < 0.08:\n",
    "                    action = 1\n",
    "                else:\n",
    "                    action = 0\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    if guideOpen and guider_net is not None:\n",
    "                        action = guider_net(torch.tensor(raw_state, dtype=torch.float32).unsqueeze(0).to(device)).argmax().item()\n",
    "                    else:\n",
    "                        action = q_net(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)).argmax().item()\n",
    "\n",
    "            # 执行动作\n",
    "            next_raw_state, reward, done, info = env.step(action)\n",
    "            step_count += 1\n",
    "            steps_total += 1\n",
    "            if max_step_count < step_count:\n",
    "                max_step_count = step_count\n",
    "            raw_state = next_raw_state\n",
    "            # 更新状态队列\n",
    "            state_queue.append(next_raw_state)\n",
    "            next_state = np.concatenate(state_queue)  # 将队列内容展平\n",
    "            reward = reward * 0.01  # 缩放奖励\n",
    "            # 得分\n",
    "            bScore = False\n",
    "            if info['score'] > score:\n",
    "                reward += 0.1  # 奖励增加\n",
    "                score = info['score']\n",
    "                bScore = True\n",
    "            if info['score'] > max_score:\n",
    "                max_score = info['score']\n",
    "                if max_score > 100:\n",
    "                    torch.save(q_net.state_dict(), bestScoreFileName) # 保存模型\n",
    "                env.render()\n",
    "                time.sleep(1 / 60)  # FPS\n",
    "                for event in pygame.event.get():\n",
    "                    pass\n",
    "            if done:\n",
    "                reward -= 1.0  # 惩罚\n",
    "            if bScore:\n",
    "                if score % aim_score == 0:\n",
    "                    replay_buffer.add(state, action, reward, next_state, True) # 得到aim_score分结束，否则轨迹越长，Q值越大，无法收敛\n",
    "                else:\n",
    "                    replay_buffer.add(state, action, reward, next_state, done)\n",
    "            else:\n",
    "                replay_buffer.add(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if total_reward > max_reward_total:\n",
    "                max_reward_total = total_reward\n",
    "            if max_interval_rewards < total_reward:\n",
    "                max_interval_rewards = total_reward\n",
    "\n",
    "            # 经验回放训练\n",
    "            if replay_buffer.size() >= batch_size:\n",
    "                training_frequency = 1\n",
    "                loss_threshold = 0.5\n",
    "                while training_frequency > 0:\n",
    "                    # 从优先级缓冲区中采样\n",
    "                    states, actions, rewards_batch, next_states, dones, weights, indices = replay_buffer.sample(batch_size, beta, device)\n",
    "\n",
    "                    q_values = q_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "                    with torch.no_grad():\n",
    "                        q_value_perInterval += q_values.mean().item() / steps_Interval\n",
    "                        best_actions = q_net(next_states).argmax(1)  # 使用当前网络选择最大Q值的动作\n",
    "                        target_q_values = rewards_batch + gamma * (1 - dones) * target_net(next_states).gather(1, best_actions.unsqueeze(1)).squeeze(1)\n",
    "                    # 计算 TD Error\n",
    "                    td_errors = target_q_values - q_values\n",
    "                    loss = (weights * td_errors.pow(2)).mean()\n",
    "                    loss_perInterval += loss.item() / steps_Interval\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # 更新优先级\n",
    "                    priorities = td_errors.abs().detach().cpu().numpy()\n",
    "                    replay_buffer.update_priorities(indices, priorities)\n",
    "                    update_step_count += 1\n",
    "                    steps_perInterval += 1\n",
    "                \n",
    "                    # 更新目标网络\n",
    "                    if update_step_count >= update_step_interval:\n",
    "                        update_step_count = 0\n",
    "                        target_net.load_state_dict(q_net.state_dict()) # 将q_net的参数复制到target_net中\n",
    "                    training_frequency -= 1\n",
    "                    if loss.item() > loss_threshold and replay_buffer.size() >= replay_buffer_capacity * 0.5 and training_frequency == 0: # 如果损失大于阈值，且经验池已足够大，则重复训练，暂停与环境互动\n",
    "                        training_frequency += delta_training_frequency\n",
    "                        loss_threshold += delta_loss_threshold\n",
    "                    if steps_perInterval >= steps_Interval:\n",
    "                        # 追加数据到 CSV 文件\n",
    "                        with open(csv_file, 'a') as f:\n",
    "                            current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                            f.write(f'{current_time_str},{episode},{steps_total},{epsilon},{loss_perInterval},{q_value_perInterval}\\n')\n",
    "                        steps_perInterval = 0\n",
    "                        loss_perInterval = 0\n",
    "                        q_value_perInterval = 0\n",
    "                    # 检查时间间隔\n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_save_time > 60:\n",
    "                        # 读取配置文件\n",
    "                        config = configparser.ConfigParser()\n",
    "                        if config.read('config.ini'):\n",
    "                            update_step_interval = config.getint('Training', 'update_step_interval')\n",
    "                            delta_training_frequency_temp = config.getint('Training', 'delta_training_frequency')\n",
    "                            if delta_training_frequency_temp >= 0:\n",
    "                                delta_training_frequency = delta_training_frequency_temp\n",
    "                            delta_loss_threshold_temp = config.getfloat('Training', 'delta_loss_threshold')\n",
    "                            if delta_loss_threshold_temp > 0:\n",
    "                                delta_loss_threshold = delta_loss_threshold_temp\n",
    "                            lr_temp = config.getfloat('Training', 'lr')\n",
    "                            if lr_temp > 0:\n",
    "                                lr = lr_temp\n",
    "                                state_dict = optimizer.state_dict()\n",
    "                                state_dict['param_groups'][0]['lr'] = lr\n",
    "                                optimizer.load_state_dict(state_dict)\n",
    "                            beta_temp = config.getfloat('Training', 'beta')\n",
    "                            if beta_temp > 0:\n",
    "                                beta = beta_temp\n",
    "                            stop_training = config.getboolean('Training', 'stop_training')\n",
    "                            guideOpen = config.getboolean('Training', 'guideOpen')\n",
    "                            \n",
    "                        # 设置保存路径和合法文件名\n",
    "                        save_path = \"./models\"\n",
    "                        os.makedirs(save_path, exist_ok=True)  # 确保路径存在\n",
    "                        current_time_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')  # 使用合法字符\n",
    "                        currentNetFile = os.path.join(save_path, f'fb_v0_no_score_{current_time_str}.pth')\n",
    "                        torch.save(q_net.state_dict(), currentNetFile) # 保存模型\n",
    "                        last_save_time = current_time\n",
    "                    if current_time - last_print_time >= print_interval:\n",
    "                        last_print_time = current_time\n",
    "                        print(f\"{episode} | {min_interval_rewards:.3f} | {max_interval_rewards:.3f} | {max_reward_total:.3f} | {epsilon:.5f} | {max_score} | {steps_total} | {lr:.8e} | {update_step_interval} | {training_frequency} | {loss_threshold:.3f} | {beta:.5f} | {replay_buffer.size()}\")\n",
    "                        min_interval_rewards = np.inf\n",
    "                        max_interval_rewards = -np.inf\n",
    "                    # 更新 beta\n",
    "                    beta = min(1.0, beta + beta_increment)\n",
    "\n",
    "        rewards.append(total_reward)  # 确保 append 正常工作\n",
    "        if min_interval_rewards > total_reward:\n",
    "            min_interval_rewards = total_reward\n",
    "        # 重置噪声\n",
    "        q_net.reset_noise()\n",
    "        target_net.reset_noise()\n",
    "        if stop_training:\n",
    "            # 把配置文件的stop_training改为False\n",
    "            config['Training']['stop_training'] = 'False'\n",
    "            with open('config.ini', 'w') as configfile:\n",
    "                config.write(configfile)\n",
    "            break\n",
    "\n",
    "    return q_net, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "class Dueling_DistributionalDQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_atoms=51):\n",
    "        super(Dueling_DistributionalDQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            NoisyLinear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            NoisyLinear(128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.V = NoisyLinear(128, num_atoms)\n",
    "        self.A = NoisyLinear(128, output_dim * num_atoms)\n",
    "        self.num_atoms = num_atoms\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        V = self.V(x).view(-1, 1, self.num_atoms)\n",
    "        A = self.A(x).view(-1, self.output_dim, self.num_atoms)\n",
    "        Q = V + (A - A.mean(dim=1, keepdim=True))\n",
    "        Q_prob = F.softmax(Q, dim=2) # 将 Q 值转换为概率分布\n",
    "        return Q_prob\n",
    "\n",
    "    def reset_noise(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, NoisyLinear):\n",
    "                m.reset_noise()\n",
    "\n",
    "def projection_distribution(next_dist, rewards, dones, gamma, atoms, v_min, v_max, delta_z, support):\n",
    "    \"\"\"\n",
    "    投影 Bellman 更新后的分布到支持点。\n",
    "    \"\"\"\n",
    "    #delta_z = (v_max - v_min) / (atoms - 1)\n",
    "    #support = torch.linspace(v_min, v_max, atoms).to(next_dist.device)  # Shape: (atoms,)\n",
    "    \n",
    "    batch_size = rewards.size(0)\n",
    "    next_support = rewards.unsqueeze(1) + gamma * support.unsqueeze(0) * (1 - dones.unsqueeze(1))  # Shape: (batch_size, atoms)\n",
    "    next_support = next_support.clamp(v_min, v_max)  # 限制范围\n",
    "\n",
    "    b = (next_support - v_min) / delta_z  # Shape: (batch_size, atoms)\n",
    "    l = b.floor().long()  # Shape: (batch_size, atoms)\n",
    "    u = b.ceil().long()  # Shape: (batch_size, atoms)\n",
    "    \n",
    "    # 修正索引的范围，确保不越界\n",
    "    l = l.clamp(0, atoms - 1)\n",
    "    u = u.clamp(0, atoms - 1)\n",
    "    \n",
    "    proj_dist = torch.zeros(batch_size, atoms).to(next_dist.device)  # Shape: (batch_size, atoms)\n",
    "\n",
    "    for i in range(atoms):  # 遍历每个支持点\n",
    "        # 注意：next_dist[:, i] 实际是 batch_size 的第 i 列 (shape: [batch_size])\n",
    "        # next_dist 应被广播以匹配 l 和 u 的维度\n",
    "        weight_left = (u[:, i] - b[:, i]).unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "        weight_right = (b[:, i] - l[:, i]).unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "        \n",
    "        proj_dist.scatter_add_(1, l[:, i].unsqueeze(1), next_dist[:, i].unsqueeze(1) * weight_left)\n",
    "        proj_dist.scatter_add_(1, u[:, i].unsqueeze(1), next_dist[:, i].unsqueeze(1) * weight_right)\n",
    "\n",
    "    # 归一化分布\n",
    "    proj_dist /= proj_dist.sum(dim=1, keepdim=True) + 1e-8  # 防止除零\n",
    "    return proj_dist\n",
    "\n",
    "def train_rainbow_dqn(env, num_episodes=500, batch_size=64, gamma=0.99, epsilon_start=1.0, epsilon_end=0.01,\n",
    "                      epsilon_decay=500, lr=1e-3, alpha=0.6, beta_start=0.4, beta_increment=1e-4,\n",
    "                      atoms=51, v_min=-10, v_max=10):\n",
    "    input_dim = env.observation_space.shape[0]\n",
    "    output_dim = env.action_space.n\n",
    "\n",
    "    q_net = Dueling_DistributionalDQN(input_dim, output_dim, num_atoms=atoms)\n",
    "    target_net = Dueling_DistributionalDQN(input_dim, output_dim, num_atoms=atoms)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=lr)\n",
    "    replay_buffer = MultiStepPrioritizedReplayBuffer(capacity=10000, alpha=alpha, n_step=3, gamma=gamma)\n",
    "\n",
    "    epsilon = epsilon_start\n",
    "    beta = beta_start\n",
    "    delta_z = (v_max - v_min) / (atoms - 1)\n",
    "    rewards = []\n",
    "    supports = torch.linspace(v_min, v_max, atoms)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        for t in range(2000):  # 每个 episode 的最大步数\n",
    "            # ε-贪婪策略\n",
    "            if random.random() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    dist = q_net(torch.tensor(state, dtype=torch.float32).unsqueeze(0))\n",
    "                    action = (dist * supports).sum(dim=2).argmax().item()\n",
    "\n",
    "            # 执行动作\n",
    "            # 渲染环境\n",
    "            #env.render()\n",
    "            #time.sleep(1 / 30)  # FPS\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            if reward < 0:\n",
    "                print(\"reward:\", reward)\n",
    "            replay_buffer.add(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            # 经验回放训练\n",
    "            if replay_buffer.size() >= batch_size:\n",
    "                # 从优先级缓冲区中采样\n",
    "                states, actions, rewards_batch, next_states, dones, weights, indices = replay_buffer.sample(batch_size, beta)\n",
    "\n",
    "                # 计算 Q 网络的分布\n",
    "                dist = q_net(states)\n",
    "                q_dist = dist[range(batch_size), actions]\n",
    "\n",
    "                # 目标分布计算\n",
    "                with torch.no_grad():\n",
    "                    # 目标网络输出分布\n",
    "                    next_dist = target_net(next_states)  # Shape: (batch_size, num_actions, atoms)\n",
    "                    # 行为网络选择动作（Double-DQN）\n",
    "                    next_q_values = (q_net(next_states) * supports.to(next_states.device)).sum(dim=2)  # Shape: (batch_size, num_actions)\n",
    "                    next_actions = next_q_values.argmax(dim=1)  # Shape: (batch_size,)\n",
    "                    # 根据行为网络选择的动作提取目标分布\n",
    "                    next_dist = next_dist[range(batch_size), next_actions]  # Shape: (batch_size, atoms)\n",
    "\n",
    "                    # 投影分布\n",
    "                    target_dist = projection_distribution(next_dist, rewards_batch, dones, gamma, atoms, v_min, v_max, delta_z, supports.to(next_states.device))\n",
    "\n",
    "                # KL 散度损失\n",
    "                loss = -(target_dist * q_dist.log()).sum(dim=1) * weights\n",
    "                loss = loss.mean()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 更新优先级\n",
    "                # Wasserstein 距离计算\n",
    "                td_errors = torch.sum((target_dist - q_dist) * supports.to(next_states.device), dim=1)  # [batch_size]\n",
    "                priorities = td_errors.abs().detach().cpu().numpy()\n",
    "                replay_buffer.update_priorities(indices, priorities)\n",
    "\n",
    "        # 更新目标网络\n",
    "        if episode % 10 == 0:\n",
    "            target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "        # 更新 epsilon\n",
    "        epsilon = max(epsilon_end, epsilon_start - episode / epsilon_decay)\n",
    "        rewards.append(total_reward)\n",
    "        # 更新 beta\n",
    "        beta = min(1.0, beta + beta_increment)\n",
    "        # 重置噪声\n",
    "        q_net.reset_noise()\n",
    "        target_net.reset_noise()\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            print(f\"Episode {episode}, Total Reward: {total_reward:.2f}, Epsilon: {epsilon:.2f}\")\n",
    "\n",
    "    return q_net, rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "引导模型已加载\n",
      "Episode | min interval reward | max interval reward | max_reward_total | Epsilon | max_score | steps_total | lr | update_step_interval | training_frequency | loss_threshold | beta | replay_buffer.size\n",
      "544 | -0.680 | 1.530 | 1.530 | 1.00000 | 1 | 49055 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 49036\n",
      "967 | -0.680 | 1.540 | 1.540 | 0.61184 | 1 | 89209 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 89190\n",
      "1362 | -0.680 | 1.480 | 1.540 | 0.25556 | 1 | 125197 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "1771 | -0.680 | 1.500 | 1.540 | 0.01000 | 1 | 160125 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2154 | -0.680 | 1.950 | 1.950 | 0.01000 | 2 | 194896 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2514 | -0.680 | 1.930 | 1.950 | 0.01000 | 2 | 229784 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "2864 | -0.680 | 2.470 | 2.470 | 0.00871 | 3 | 264357 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3103 | -0.680 | 29.420 | 29.420 | 0.00575 | 61 | 297257 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3470 | -0.680 | 1.290 | 29.420 | 0.00266 | 61 | 331512 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "3815 | -0.680 | 1.990 | 29.420 | 0.00100 | 61 | 366596 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4155 | -0.680 | 1.760 | 29.420 | 0.00100 | 61 | 401259 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4499 | -0.680 | 1.760 | 29.420 | 0.00100 | 61 | 434507 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "4815 | -0.680 | 2.150 | 29.420 | 0.00069 | 61 | 467428 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5114 | -0.680 | 2.960 | 29.420 | 0.00010 | 61 | 500114 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5384 | -0.680 | 4.330 | 29.420 | 0.00008 | 61 | 532472 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5613 | -0.680 | 5.310 | 29.420 | 0.00006 | 61 | 564921 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "5853 | -0.680 | 5.220 | 29.420 | 0.00003 | 61 | 597874 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6079 | -0.680 | 6.460 | 29.420 | 0.00001 | 61 | 630557 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6276 | 0.010 | 7.350 | 29.420 | 0.00000 | 61 | 664157 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6386 | 0.010 | 15.810 | 29.420 | 0.00000 | 61 | 696292 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6496 | -0.680 | 16.490 | 29.420 | 0.00000 | 61 | 728297 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6595 | 0.010 | 21.190 | 29.420 | 0.00000 | 61 | 760531 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6663 | 0.030 | 22.610 | 29.420 | 0.00000 | 61 | 794870 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6732 | 0.010 | 45.850 | 45.850 | 0.00000 | 96 | 829300 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6773 | -0.680 | 56.910 | 56.910 | 0.00000 | 119 | 864059 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6831 | -0.550 | 39.530 | 56.910 | 0.00000 | 119 | 899422 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6881 | 0.010 | 63.490 | 63.490 | 0.00000 | 133 | 932479 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6916 | 0.010 | 63.030 | 63.490 | 0.00000 | 133 | 965252 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6958 | -0.680 | 68.190 | 68.190 | 0.00000 | 143 | 997799 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "6986 | 0.050 | 63.030 | 68.190 | 0.00000 | 143 | 1030680 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7011 | 0.300 | 58.790 | 68.190 | 0.00000 | 143 | 1064303 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7046 | 0.040 | 53.460 | 68.190 | 0.00000 | 143 | 1097893 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7069 | 0.470 | 59.270 | 68.190 | 0.00000 | 143 | 1133102 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7081 | 0.470 | 179.590 | 179.590 | 0.00000 | 380 | 1169344 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7114 | 0.470 | 80.890 | 179.590 | 0.00000 | 380 | 1206230 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7137 | 0.530 | 63.800 | 179.590 | 0.00000 | 380 | 1237760 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7150 | -0.680 | 93.670 | 179.590 | 0.00000 | 380 | 1272131 | 1.00000000e-05 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7185 | 0.010 | 85.110 | 179.590 | 0.00000 | 380 | 1307569 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7215 | 0.020 | 81.380 | 179.590 | 0.00000 | 380 | 1343280 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7236 | 0.540 | 69.130 | 179.590 | 0.00000 | 380 | 1378554 | 1.00000000e-05 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "7252 | 0.470 | 133.050 | 179.590 | 0.00000 | 380 | 1413768 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7269 | 0.470 | 147.630 | 179.590 | 0.00000 | 380 | 1449156 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7289 | 0.010 | 68.220 | 179.590 | 0.00000 | 380 | 1480343 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7302 | 0.470 | 96.240 | 179.590 | 0.00000 | 380 | 1511467 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7316 | 0.470 | 71.950 | 179.590 | 0.00000 | 380 | 1540446 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7336 | 0.020 | 96.240 | 179.590 | 0.00000 | 380 | 1569927 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7353 | 0.470 | 101.090 | 179.590 | 0.00000 | 380 | 1600871 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7362 | 6.100 | 98.750 | 179.590 | 0.00000 | 380 | 1635639 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7374 | 0.940 | 83.230 | 179.590 | 0.00000 | 380 | 1670434 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7389 | 0.470 | 146.210 | 179.590 | 0.00000 | 380 | 1707084 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7399 | 3.130 | 109.600 | 179.590 | 0.00000 | 380 | 1744985 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7411 | -0.680 | 147.150 | 179.590 | 0.00000 | 380 | 1782522 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7424 | 0.470 | 174.410 | 179.590 | 0.00000 | 380 | 1820344 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7439 | 0.540 | 65.930 | 179.590 | 0.00000 | 380 | 1858249 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7456 | 0.010 | 162.980 | 179.590 | 0.00000 | 380 | 1895995 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7468 | 3.280 | 104.850 | 179.590 | 0.00000 | 380 | 1932349 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7476 | 2.190 | 133.960 | 179.590 | 0.00000 | 380 | 1969415 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7497 | 0.470 | 136.350 | 179.590 | 0.00000 | 380 | 2006823 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7511 | 0.990 | 104.700 | 179.590 | 0.00000 | 380 | 2043692 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7520 | 3.590 | 111.430 | 179.590 | 0.00000 | 380 | 2080738 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7536 | 0.470 | 97.330 | 179.590 | 0.00000 | 380 | 2117351 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7549 | 0.470 | 154.670 | 179.590 | 0.00000 | 380 | 2153965 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7562 | 0.470 | 127.890 | 179.590 | 0.00000 | 380 | 2190383 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7571 | 6.580 | 134.300 | 179.590 | 0.00000 | 380 | 2226963 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7592 | -0.680 | 123.650 | 179.590 | 0.00000 | 380 | 2263627 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7603 | 0.470 | 110.800 | 179.590 | 0.00000 | 380 | 2300199 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7609 | 6.890 | 168.310 | 179.590 | 0.00000 | 380 | 2336489 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7628 | 0.470 | 133.530 | 179.590 | 0.00000 | 380 | 2371835 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7640 | 0.470 | 96.390 | 179.590 | 0.00000 | 380 | 2408094 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7644 | 19.740 | 210.130 | 210.130 | 0.00000 | 445 | 2445139 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7664 | -0.680 | 147.150 | 210.130 | 0.00000 | 445 | 2481532 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7678 | 1.250 | 112.370 | 210.130 | 0.00000 | 445 | 2518124 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7696 | 0.010 | 104.390 | 210.130 | 0.00000 | 445 | 2554487 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7710 | 0.020 | 190.700 | 210.130 | 0.00000 | 445 | 2591129 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7721 | 0.470 | 130.230 | 210.130 | 0.00000 | 445 | 2628148 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7728 | 14.100 | 200.730 | 210.130 | 0.00000 | 445 | 2664468 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7734 | 20.200 | 171.480 | 210.130 | 0.00000 | 445 | 2700948 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7742 | 22.820 | 174.260 | 210.130 | 0.00000 | 445 | 2737450 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7745 | 83.180 | 159.210 | 210.130 | 0.00000 | 445 | 2773671 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7748 | -0.680 | 465.810 | 465.810 | 0.00000 | 989 | 2807164 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7760 | 0.470 | 119.820 | 465.810 | 0.00000 | 989 | 2843073 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7766 | 7.040 | 144.180 | 465.810 | 0.00000 | 989 | 2879393 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7776 | 1.010 | 214.370 | 465.810 | 0.00000 | 989 | 2915940 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7787 | 4.220 | 174.890 | 465.810 | 0.00000 | 989 | 2952981 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7794 | 4.220 | 112.680 | 465.810 | 0.00000 | 989 | 2989476 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7803 | 0.270 | 166.720 | 465.810 | 0.00000 | 989 | 3026172 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7814 | 7.800 | 132.170 | 465.810 | 0.00000 | 989 | 3063067 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7819 | 22.390 | 178.650 | 465.810 | 0.00000 | 989 | 3100049 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7824 | 17.380 | 277.180 | 465.810 | 0.00000 | 989 | 3136676 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7829 | 11.740 | 290.340 | 465.810 | 0.00000 | 989 | 3173763 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7844 | 0.470 | 134.780 | 465.810 | 0.00000 | 989 | 3210727 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7853 | 7.980 | 97.810 | 465.810 | 0.00000 | 989 | 3246731 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7867 | 0.470 | 79.470 | 465.810 | 0.00000 | 989 | 3283209 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7875 | 6.100 | 229.930 | 465.810 | 0.00000 | 989 | 3319796 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7883 | -0.680 | 210.610 | 465.810 | 0.00000 | 989 | 3356046 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7891 | 0.470 | 167.200 | 465.810 | 0.00000 | 989 | 3392622 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7898 | 15.980 | 146.690 | 465.810 | 0.00000 | 989 | 3428964 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7907 | 0.940 | 165.950 | 465.810 | 0.00000 | 989 | 3465901 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7913 | 5.640 | 176.770 | 465.810 | 0.00000 | 989 | 3502836 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7916 | 8.290 | 408.470 | 465.810 | 0.00000 | 989 | 3539438 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7926 | 0.470 | 127.410 | 465.810 | 0.00000 | 989 | 3576297 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7932 | 0.470 | 143.390 | 465.810 | 0.00000 | 989 | 3613418 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7938 | 3.130 | 192.270 | 465.810 | 0.00000 | 989 | 3650407 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7951 | 0.470 | 97.330 | 465.810 | 0.00000 | 989 | 3686400 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7958 | 1.400 | 129.350 | 465.810 | 0.00000 | 989 | 3722931 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7975 | 0.510 | 107.730 | 465.810 | 0.00000 | 989 | 3759379 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7982 | 20.510 | 107.670 | 465.810 | 0.00000 | 989 | 3796035 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7990 | 5.160 | 173.950 | 465.810 | 0.00000 | 989 | 3832890 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "7994 | 2.340 | 278.600 | 465.810 | 0.00000 | 989 | 3869633 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8001 | 2.340 | 190.230 | 465.810 | 0.00000 | 989 | 3906436 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8010 | 0.470 | 114.730 | 465.810 | 0.00000 | 989 | 3943402 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8017 | 27.260 | 154.670 | 465.810 | 0.00000 | 989 | 3980341 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8025 | 7.040 | 179.590 | 465.810 | 0.00000 | 989 | 4017304 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8035 | 0.470 | 120.830 | 465.810 | 0.00000 | 989 | 4054229 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8047 | 0.470 | 130.230 | 465.810 | 0.00000 | 989 | 4090960 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8054 | 6.100 | 229.870 | 465.810 | 0.00000 | 989 | 4127149 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8064 | 0.470 | 167.370 | 465.810 | 0.00000 | 989 | 4163773 | 1.00000000e-05 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8069 | 63.440 | 157.800 | 465.810 | 0.00000 | 989 | 4200798 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8080 | 2.180 | 87.770 | 465.810 | 0.00000 | 989 | 4237560 | 1.00000000e-05 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8088 | 1.690 | 130.540 | 465.810 | 0.00000 | 989 | 4274677 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8092 | 13.160 | 192.270 | 465.810 | 0.00000 | 989 | 4311365 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8099 | 0.470 | 181.930 | 465.810 | 0.00000 | 989 | 4348311 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8102 | 83.660 | 165.010 | 465.810 | 0.00000 | 989 | 4385120 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8114 | 0.470 | 105.790 | 465.810 | 0.00000 | 989 | 4421889 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8116 | 93.520 | 257.440 | 465.810 | 0.00000 | 989 | 4458800 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8119 | 0.940 | 343.610 | 465.810 | 0.00000 | 989 | 4495798 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8123 | 73.780 | 175.200 | 465.810 | 0.00000 | 989 | 4532564 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8133 | 2.650 | 100.150 | 465.810 | 0.00000 | 989 | 4568547 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8139 | 15.500 | 184.660 | 465.810 | 0.00000 | 989 | 4604917 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8150 | 0.470 | 239.750 | 465.810 | 0.00000 | 989 | 4641649 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8163 | 0.470 | 88.870 | 465.810 | 0.00000 | 989 | 4678361 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8173 | 0.470 | 113.310 | 465.810 | 0.00000 | 989 | 4715501 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8179 | 0.470 | 217.500 | 465.810 | 0.00000 | 989 | 4751967 | 1.00000000e-05 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8190 | 2.340 | 102.340 | 465.810 | 0.00000 | 989 | 4788672 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8197 | 1.880 | 141.360 | 465.810 | 0.00000 | 989 | 4825519 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8211 | 0.470 | 72.260 | 465.810 | 0.00000 | 989 | 4862245 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8217 | 1.250 | 256.260 | 465.810 | 0.00000 | 989 | 4899134 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8224 | 2.650 | 299.740 | 465.810 | 0.00000 | 989 | 4936197 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8230 | 0.470 | 154.670 | 465.810 | 0.00000 | 989 | 4972923 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8235 | 3.280 | 182.870 | 465.810 | 0.00000 | 989 | 5008809 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8240 | 13.620 | 271.230 | 465.810 | 0.00000 | 989 | 5045123 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8250 | 0.470 | 230.180 | 465.810 | 0.00000 | 989 | 5082607 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8252 | 48.710 | 231.590 | 465.810 | 0.00000 | 989 | 5119174 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8267 | -0.680 | 240.990 | 465.810 | 0.00000 | 989 | 5155856 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8273 | 8.920 | 204.490 | 465.810 | 0.00000 | 989 | 5192371 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8280 | 12.680 | 173.010 | 465.810 | 0.00000 | 989 | 5229145 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8288 | 2.340 | 115.030 | 465.810 | 0.00000 | 989 | 5265984 | 1.00000000e-05 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8296 | 0.470 | 127.410 | 465.810 | 0.00000 | 989 | 5302762 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8302 | 30.540 | 126.470 | 465.810 | 0.00000 | 989 | 5339492 | 1.00000000e-05 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8307 | 0.470 | 191.330 | 465.810 | 0.00000 | 989 | 5376356 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8312 | 9.860 | 201.200 | 465.810 | 0.00000 | 989 | 5413042 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8321 | 0.470 | 270.400 | 465.810 | 0.00000 | 989 | 5448725 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8325 | 11.740 | 277.810 | 465.810 | 0.00000 | 989 | 5485146 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8332 | 0.470 | 147.580 | 465.810 | 0.00000 | 989 | 5522050 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8344 | 7.330 | 184.750 | 465.810 | 0.00000 | 989 | 5558777 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8346 | 62.500 | 390.180 | 465.810 | 0.00000 | 989 | 5595606 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8353 | 1.220 | 395.610 | 465.810 | 0.00000 | 989 | 5632158 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8357 | 51.700 | 368.990 | 465.810 | 0.00000 | 989 | 5669023 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8367 | 3.280 | 121.620 | 465.810 | 0.00000 | 989 | 5705947 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8374 | 0.470 | 171.130 | 465.810 | 0.00000 | 989 | 5742734 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8377 | 25.210 | 207.310 | 465.810 | 0.00000 | 989 | 5779331 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8382 | 47.000 | 173.470 | 465.810 | 0.00000 | 989 | 5816016 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8388 | -0.680 | 194.490 | 465.810 | 0.00000 | 989 | 5852767 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8392 | 56.230 | 260.430 | 465.810 | 0.00000 | 989 | 5888607 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8399 | 0.470 | 165.010 | 465.810 | 0.00000 | 989 | 5925212 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8402 | 0.940 | 310.710 | 465.810 | 0.00000 | 989 | 5961940 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8408 | 3.760 | 234.570 | 465.810 | 0.00000 | 989 | 5998394 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8412 | 19.260 | 266.530 | 465.810 | 0.00000 | 989 | 6034339 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8417 | 0.940 | 171.590 | 465.810 | 0.00000 | 989 | 6070395 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8425 | 1.400 | 292.700 | 465.810 | 0.00000 | 989 | 6106915 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8432 | 20.020 | 98.270 | 465.810 | 0.00000 | 989 | 6143755 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8437 | 14.860 | 119.720 | 465.810 | 0.00000 | 989 | 6180482 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8448 | 4.220 | 213.890 | 465.810 | 0.00000 | 989 | 6217407 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8451 | 1.880 | 299.430 | 465.810 | 0.00000 | 989 | 6254607 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8466 | 2.340 | 110.340 | 465.810 | 0.00000 | 989 | 6291538 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8477 | 1.400 | 120.830 | 465.810 | 0.00000 | 989 | 6327604 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8483 | 4.530 | 306.490 | 465.810 | 0.00000 | 989 | 6364065 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8485 | 86.000 | 298.980 | 465.810 | 0.00000 | 989 | 6400683 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8494 | -0.680 | 382.440 | 465.810 | 0.00000 | 989 | 6437184 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8496 | 99.160 | 260.440 | 465.810 | 0.00000 | 989 | 6473915 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8503 | 22.380 | 300.220 | 465.810 | 0.00000 | 989 | 6510444 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8506 | 0.470 | 354.910 | 465.810 | 0.00000 | 989 | 6547329 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8513 | 0.470 | 394.370 | 465.810 | 0.00000 | 989 | 6584213 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8519 | 12.680 | 207.200 | 465.810 | 0.00000 | 989 | 6621006 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8520 | 445.840 | 446.830 | 465.810 | 0.00000 | 989 | 6657769 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8528 | 0.290 | 310.250 | 465.810 | 0.00000 | 989 | 6694776 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8534 | 2.340 | 313.980 | 465.810 | 0.00000 | 989 | 6729388 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8536 | 296.870 | 368.530 | 465.810 | 0.00000 | 989 | 6761008 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8541 | 4.060 | 165.280 | 465.810 | 0.00000 | 989 | 6794360 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8545 | 42.610 | 252.430 | 465.810 | 0.00000 | 989 | 6829935 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8547 | 82.240 | 201.220 | 465.810 | 0.00000 | 989 | 6866075 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8550 | 12.680 | 375.570 | 465.810 | 0.00000 | 989 | 6902792 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8552 | 44.930 | 279.690 | 465.810 | 0.00000 | 989 | 6939264 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8554 | 274.480 | 313.070 | 465.810 | 0.00000 | 989 | 6975970 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8555 | 433.650 | 434.640 | 465.810 | 0.00000 | 989 | 7012478 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8560 | 7.040 | 329.820 | 465.810 | 0.00000 | 989 | 7048888 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8564 | 74.720 | 170.650 | 465.810 | 0.00000 | 989 | 7085391 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8568 | 3.130 | 177.710 | 465.810 | 0.00000 | 989 | 7122386 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8574 | 3.280 | 306.010 | 465.810 | 0.00000 | 989 | 7159119 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8577 | 0.470 | 323.870 | 465.810 | 0.00000 | 989 | 7194679 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8580 | 9.860 | 230.810 | 465.810 | 0.00000 | 989 | 7230431 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8581 | 415.480 | 416.470 | 465.810 | 0.00000 | 989 | 7266872 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8590 | 0.470 | 201.670 | 465.810 | 0.00000 | 989 | 7303082 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8593 | 39.000 | 202.920 | 465.810 | 0.00000 | 989 | 7339842 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8595 | 247.220 | 287.690 | 465.810 | 0.00000 | 989 | 7376575 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8595 | inf | 532.330 | 532.330 | 0.00000 | 1131 | 7412715 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8598 | 44.010 | 755.810 | 755.810 | 0.00000 | 1606 | 7447827 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8603 | 1.400 | 255.290 | 755.810 | 0.00000 | 1606 | 7484359 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8604 | 693.720 | 694.710 | 755.810 | 0.00000 | 1606 | 7520871 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8607 | 95.400 | 148.450 | 755.810 | 0.00000 | 1606 | 7557284 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8612 | -0.680 | 247.100 | 755.810 | 0.00000 | 1606 | 7593450 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8613 | 157.440 | 307.320 | 755.810 | 0.00000 | 1606 | 7628762 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8618 | 2.340 | 360.530 | 755.810 | 0.00000 | 1606 | 7664402 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8619 | 62.500 | 391.600 | 755.810 | 0.00000 | 1606 | 7700116 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8622 | 23.500 | 435.580 | 755.810 | 0.00000 | 1606 | 7735999 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8629 | 0.470 | 282.990 | 755.810 | 0.00000 | 1606 | 7772016 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8633 | 51.700 | 174.720 | 755.810 | 0.00000 | 1606 | 7807395 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8637 | 41.820 | 149.030 | 755.810 | 0.00000 | 1606 | 7843299 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8647 | 0.470 | 110.030 | 755.810 | 0.00000 | 1606 | 7879017 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8656 | 0.010 | 118.800 | 755.810 | 0.00000 | 1606 | 7912849 | 1.00000000e-05 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8663 | 0.940 | 198.850 | 755.810 | 0.00000 | 1606 | 7945712 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8668 | 4.700 | 165.010 | 755.810 | 0.00000 | 1606 | 7978564 | 1.00000000e-05 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "8671 | 37.120 | 160.350 | 755.810 | 0.00000 | 1606 | 8011341 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8674 | 126.900 | 256.500 | 755.810 | 0.00000 | 1606 | 8043267 | 1.00000000e-05 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8675 | 291.860 | 292.850 | 755.810 | 0.00000 | 1606 | 8075472 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8678 | 3.130 | 452.500 | 755.810 | 0.00000 | 1606 | 8108041 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8681 | 30.080 | 352.550 | 755.810 | 0.00000 | 1606 | 8140534 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8681 | inf | 425.350 | 755.810 | 0.00000 | 1606 | 8173141 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8684 | 16.740 | 496.830 | 755.810 | 0.00000 | 1606 | 8206180 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8690 | 12.680 | 180.960 | 755.810 | 0.00000 | 1606 | 8240901 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8690 | inf | 601.480 | 755.810 | 0.00000 | 1606 | 8274003 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8691 | 633.080 | 634.070 | 755.810 | 0.00000 | 1606 | 8306776 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8691 | inf | 798.400 | 798.400 | 0.00000 | 1697 | 8339443 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8693 | 108.100 | 880.350 | 880.350 | 0.00000 | 1871 | 8372290 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8695 | 6.620 | 631.750 | 880.350 | 0.00000 | 1871 | 8407889 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8697 | 49.850 | 231.750 | 880.350 | 0.00000 | 1871 | 8441283 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8697 | inf | 534.510 | 880.350 | 0.00000 | 1871 | 8469279 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8700 | 19.740 | 615.270 | 880.350 | 0.00000 | 1871 | 8497266 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8700 | inf | 454.140 | 880.350 | 0.00000 | 1871 | 8525114 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8703 | 0.940 | 638.770 | 880.350 | 0.00000 | 1871 | 8553206 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8705 | 121.720 | 212.950 | 880.350 | 0.00000 | 1871 | 8580223 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8708 | 12.260 | 265.810 | 880.350 | 0.00000 | 1871 | 8604378 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8709 | 397.930 | 398.920 | 880.350 | 0.00000 | 1871 | 8627407 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8714 | 15.980 | 186.630 | 880.350 | 0.00000 | 1871 | 8655194 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8716 | 69.560 | 264.190 | 880.350 | 0.00000 | 1871 | 8685479 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8719 | 54.040 | 221.410 | 880.350 | 0.00000 | 1871 | 8715877 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8721 | 64.380 | 266.530 | 880.350 | 0.00000 | 1871 | 8747033 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8726 | 26.340 | 162.190 | 880.350 | 0.00000 | 1871 | 8777802 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8728 | 82.720 | 219.000 | 880.350 | 0.00000 | 1871 | 8811559 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8731 | 1.210 | 446.840 | 880.350 | 0.00000 | 1871 | 8844063 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8732 | 513.700 | 514.690 | 880.350 | 0.00000 | 1871 | 8876149 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8734 | 3.590 | 399.070 | 880.350 | 0.00000 | 1871 | 8909478 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8737 | 5.160 | 295.210 | 880.350 | 0.00000 | 1871 | 8942204 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8737 | inf | 537.330 | 880.350 | 0.00000 | 1871 | 8974551 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8738 | 934.820 | 935.810 | 935.810 | 0.00000 | 1989 | 9007604 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8738 | inf | 434.100 | 935.810 | 0.00000 | 1989 | 9040110 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8740 | 122.510 | 542.890 | 935.810 | 0.00000 | 1989 | 9070139 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8744 | 19.260 | 212.010 | 935.810 | 0.00000 | 1989 | 9105879 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8745 | 583.740 | 584.730 | 935.810 | 0.00000 | 1989 | 9141416 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8746 | 183.760 | 287.760 | 935.810 | 0.00000 | 1989 | 9176395 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8749 | 21.140 | 352.070 | 935.810 | 0.00000 | 1989 | 9212055 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8749 | inf | 517.380 | 935.810 | 0.00000 | 1989 | 9248155 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8758 | 4.520 | 557.930 | 935.810 | 0.00000 | 1989 | 9284469 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8760 | 59.680 | 236.930 | 935.810 | 0.00000 | 1989 | 9319903 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8764 | 5.200 | 318.310 | 935.810 | 0.00000 | 1989 | 9351937 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8766 | 29.600 | 423.050 | 935.810 | 0.00000 | 1989 | 9383877 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8770 | 2.830 | 456.410 | 935.810 | 0.00000 | 1989 | 9415973 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8771 | 465.300 | 466.290 | 935.810 | 0.00000 | 1989 | 9448120 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8772 | 380.700 | 381.690 | 935.810 | 0.00000 | 1989 | 9479978 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8774 | 33.360 | 329.050 | 935.810 | 0.00000 | 1989 | 9509457 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8776 | 25.840 | 329.990 | 935.810 | 0.00000 | 1989 | 9539781 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8779 | 63.440 | 146.690 | 935.810 | 0.00000 | 1989 | 9570250 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8779 | inf | 516.820 | 935.810 | 0.00000 | 1989 | 9601857 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8782 | 36.180 | 748.750 | 935.810 | 0.00000 | 1989 | 9633789 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8786 | 33.840 | 136.810 | 935.810 | 0.00000 | 1989 | 9666162 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8787 | 232.640 | 287.310 | 935.810 | 0.00000 | 1989 | 9697402 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8789 | 82.720 | 512.810 | 935.810 | 0.00000 | 1989 | 9729086 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8790 | 345.440 | 346.430 | 935.810 | 0.00000 | 1989 | 9761232 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8793 | 53.100 | 264.650 | 935.810 | 0.00000 | 1989 | 9792967 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8793 | inf | 525.460 | 935.810 | 0.00000 | 1989 | 9824248 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8802 | -0.680 | 745.780 | 935.810 | 0.00000 | 1989 | 9855302 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8806 | 12.220 | 228.930 | 935.810 | 0.00000 | 1989 | 9885608 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8809 | 25.380 | 310.760 | 935.810 | 0.00000 | 1989 | 9915958 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8813 | 22.080 | 351.610 | 935.810 | 0.00000 | 1989 | 9945083 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8819 | 0.470 | 197.910 | 935.810 | 0.00000 | 1989 | 9974754 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8822 | 30.540 | 188.040 | 935.810 | 0.00000 | 1989 | 10005102 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8826 | 12.680 | 227.360 | 935.810 | 0.00000 | 1989 | 10035052 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8836 | 0.020 | 154.210 | 935.810 | 0.00000 | 1989 | 10065048 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "8896 | 0.010 | 76.650 | 935.810 | 0.00000 | 1989 | 10095363 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9192 | 0.010 | 2.410 | 935.810 | 0.00000 | 1989 | 10126214 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "9485 | 0.010 | 2.870 | 935.810 | 0.00000 | 1989 | 10156433 | 1.00000000e-06 | 100 | 0 | 0.600 | 1.00000 | 100000\n",
      "9777 | 0.010 | 2.880 | 935.810 | 0.00000 | 1989 | 10187553 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "10085 | 0.010 | 1.930 | 935.810 | 0.00000 | 1989 | 10218742 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "10391 | 0.010 | 1.220 | 935.810 | 0.00000 | 1989 | 10249707 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "10695 | 0.010 | 1.100 | 935.810 | 0.00000 | 1989 | 10280482 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "10996 | 0.010 | 1.060 | 935.810 | 0.00000 | 1989 | 10310929 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n",
      "11325 | 0.010 | 1.210 | 935.810 | 0.00000 | 1989 | 10344236 | 1.00000000e-06 | 100 | 0 | 0.500 | 1.00000 | 100000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import flappy_bird_gym\n",
    "\n",
    "# 确保环境是 FlappyBird-v0\n",
    "env = gym.make(\"FlappyBird-v0\")\n",
    "import os\n",
    "import pygame\n",
    "\n",
    "# 将声音输出重定向到\"无声设备\"\n",
    "os.environ[\"SDL_AUDIODRIVER\"] = \"dummy\"  # 设置虚拟音频驱动\n",
    "pygame.mixer.quit()  # 重新初始化以应用设置\n",
    "\n",
    "# 定义支持点范围\n",
    "v_min = -1.0\n",
    "v_max = 11.5\n",
    "atoms = 51\n",
    "\n",
    "# 训练网络\n",
    "q_net, rewards = train_dueling_dqn_noise_MultiStep_PER(\n",
    "    env,\n",
    "    num_episodes=50000,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    epsilon_schedule=[(0, 1), (50000, 1), (150000, 0.01), (250000, 0.01), (350000, 0.001), (450000, 0.001), (500000, 0.0001), (650000, 0.0)],\n",
    "    lr=1e-4,\n",
    "    alpha=0.6,\n",
    "    beta_start=0.4,\n",
    "    beta_increment=1e-4\n",
    ")\n",
    "plot_dataList(rewards)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import flappy_bird_gym\n",
    "import pygame\n",
    "\n",
    "if os.path.exists(fileName):  # 判断是否存在fileName文件\n",
    "    env = flappy_bird_gym.make(\"FlappyBird-v0\")\n",
    "    input_dim = env.observation_space.shape[0]\n",
    "    output_dim = env.action_space.n\n",
    "    q_net = Dueling_NoisyDQN(input_dim, output_dim)\n",
    "    q_net.load_state_dict(torch.load(fileName, weights_only=True))\n",
    "    q_net.eval()\n",
    "    print(\"模型已加载\")\n",
    "    obs = env.reset()\n",
    "    bExit = False\n",
    "    current_score = 0\n",
    "    min_steps_between_flaps = 999999\n",
    "    steps_between_flaps = 0\n",
    "    while bExit == False:\n",
    "        obs = tuple(obs)\n",
    "        # Next action:\n",
    "        # (feed the observation to your agent here)\n",
    "        action = q_net(torch.tensor(obs, dtype=torch.float32).unsqueeze(0)).argmax().item()\n",
    "\n",
    "        # Processing:\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        steps_between_flaps += 1\n",
    "        if info['score'] > current_score:\n",
    "            current_score = info['score']\n",
    "            if steps_between_flaps < min_steps_between_flaps:\n",
    "                min_steps_between_flaps = steps_between_flaps\n",
    "            steps_between_flaps = 0\n",
    "        # Rendering the game:\n",
    "        # (remove this two lines during training)\n",
    "        env.render()\n",
    "        time.sleep(1 / 30)  # FPS\n",
    "\n",
    "        # 处理 pygame 事件队列，防止窗口卡死\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                env.close()\n",
    "                #exit()\n",
    "                bExit = True\n",
    "                done = True\n",
    "        \n",
    "        # Checking if the player is still alive\n",
    "        if done:\n",
    "            print(f\"score: {info['score']}\")\n",
    "            print(\"Game Over\")\n",
    "            steps_between_flaps = 0\n",
    "            obs = env.reset()\n",
    "\n",
    "    env.close()\n",
    "    print(f\"min_steps_between_flaps: {min_steps_between_flaps}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
